{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paper': tensor([[0.0000, 0.0000, 0.0000, 0.0484, 0.0000, 0.2737, 0.4100, 0.0000, 0.0000,\n",
      "         0.4818, 0.4025, 0.0000, 0.0000, 0.0000, 0.0471, 0.0000, 0.1748, 0.1864,\n",
      "         0.0116, 0.0000, 0.0954, 0.1594, 0.0037, 0.1770, 0.0000, 0.0243, 0.0000,\n",
      "         0.0000, 0.6097, 0.2226, 0.1705, 0.0000],\n",
      "        [0.4053, 0.2400, 0.4387, 0.5107, 0.2151, 0.2483, 0.5080, 0.2909, 0.1000,\n",
      "         0.1947, 0.0000, 0.0000, 0.3962, 0.0000, 0.0000, 0.2419, 0.6716, 0.3439,\n",
      "         0.2713, 0.2417, 0.0401, 0.0000, 0.1971, 0.0000, 0.1814, 0.7656, 0.2257,\n",
      "         0.1830, 0.0000, 0.5000, 0.0000, 0.7319],\n",
      "        [0.3988, 0.0000, 0.0000, 0.5462, 0.0000, 0.1617, 0.1538, 0.0000, 0.0107,\n",
      "         0.1540, 0.4406, 0.0000, 0.0713, 0.0000, 0.0000, 0.0000, 0.1536, 0.3736,\n",
      "         0.0000, 0.3704, 0.0000, 0.0000, 0.4773, 0.2939, 0.1785, 0.0000, 0.3888,\n",
      "         0.0000, 0.0304, 0.0000, 0.0000, 0.0400],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000]], grad_fn=<SumBackward1>), 'author': tensor([[0.8142, 0.4821, 0.7927, 0.0000, 0.4320, 0.2889, 0.6471, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.3803, 0.0000, 0.0000, 0.0000, 0.0000, 0.5274,\n",
      "         0.5449, 0.0000, 0.0000, 0.0000, 0.3959, 0.0000, 0.0000, 0.7312, 0.0000,\n",
      "         0.0438, 0.0000, 0.1433, 0.0000, 1.1298],\n",
      "        [0.1582, 0.5318, 0.0000, 0.0084, 0.0000, 0.0000, 0.0648, 0.1905, 0.1754,\n",
      "         0.0830, 0.4472, 0.1969, 0.0000, 0.0000, 0.3186, 0.0000, 0.0000, 0.0948,\n",
      "         0.0000, 0.5469, 0.4654, 0.0000, 0.0000, 0.0000, 0.6975, 0.9577, 0.0000,\n",
      "         0.0000, 0.6018, 0.0803, 0.8769, 0.0000]], grad_fn=<SumBackward1>)}\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import HANConv\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "\n",
    "# 定义输入维度和输出维度\n",
    "in_channels = {'paper': 128, 'author': 64}\n",
    "out_channels = 32\n",
    "\n",
    "# 定义元路径\n",
    "metadatas = [\n",
    "    ['author', 'paper'],\n",
    "    [('paper', 'cites', 'paper'),('paper', 'written-by', 'author'), ('author', 'written-by', 'paper')]\n",
    "]\n",
    "\n",
    "# 初始化 HANConv\n",
    "conv = HANConv(in_channels, out_channels, metadatas)\n",
    "\n",
    "# 示例数据\n",
    "x_dict = {'paper': torch.randn(4, 128), 'author': torch.randn(2, 64)}\n",
    "edge_index_dict = {\n",
    "    ('paper', 'written-by', 'author'): torch.tensor([[0, 3], [0, 1]], dtype=torch.long),\n",
    "    ('author', 'written-by', 'paper'): torch.tensor([[0, 1], [0, 1]], dtype=torch.long),\n",
    "    ('paper', 'cites', 'paper'): torch.tensor([[0, 1], [1, 2]], dtype=torch.long),\n",
    "}\n",
    "\n",
    "# 数据对象\n",
    "data = Data(x_dict=x_dict, edge_index_dict=edge_index_dict)\n",
    "\n",
    "# 前向传播\n",
    "out = conv(x_dict, edge_index_dict)\n",
    "\n",
    "# 输出结果\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## heteroconv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() got multiple values for argument 'x_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/notebooks/pytorch_timeseries/notebooks/05_han_conv.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B251-internal-yww-jupyter/notebooks/pytorch_timeseries/notebooks/05_han_conv.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m hetero_conv \u001b[39m=\u001b[39m HeteroConv({\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B251-internal-yww-jupyter/notebooks/pytorch_timeseries/notebooks/05_han_conv.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mpaper\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcites\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpaper\u001b[39m\u001b[39m'\u001b[39m): FAConv(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m64\u001b[39m, add_self_loops\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B251-internal-yww-jupyter/notebooks/pytorch_timeseries/notebooks/05_han_conv.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mauthor\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwrites\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpaper\u001b[39m\u001b[39m'\u001b[39m): FAConv(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m64\u001b[39m, add_self_loops\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B251-internal-yww-jupyter/notebooks/pytorch_timeseries/notebooks/05_han_conv.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mpaper\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwritten-by\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mauthor\u001b[39m\u001b[39m'\u001b[39m): FAConv(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m64\u001b[39m, add_self_loops\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B251-internal-yww-jupyter/notebooks/pytorch_timeseries/notebooks/05_han_conv.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m }, aggr\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B251-internal-yww-jupyter/notebooks/pytorch_timeseries/notebooks/05_han_conv.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m x_0_dict \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mpaper\u001b[39m\u001b[39m'\u001b[39m: torch\u001b[39m.\u001b[39mrandn(\u001b[39m4\u001b[39m, \u001b[39m128\u001b[39m), \u001b[39m'\u001b[39m\u001b[39mauthor\u001b[39m\u001b[39m'\u001b[39m: torch\u001b[39m.\u001b[39mrandn(\u001b[39m2\u001b[39m, \u001b[39m64\u001b[39m)}\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B251-internal-yww-jupyter/notebooks/pytorch_timeseries/notebooks/05_han_conv.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m out_dict \u001b[39m=\u001b[39m hetero_conv(x_0_dict\u001b[39m=\u001b[39;49mx_0_dict, x_dict\u001b[39m=\u001b[39;49mx_dict, edge_index_dict\u001b[39m=\u001b[39;49medge_index_dict, edge_weight_dict\u001b[39m=\u001b[39;49medge_weight_dict)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B251-internal-yww-jupyter/notebooks/pytorch_timeseries/notebooks/05_han_conv.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlist\u001b[39m(out_dict\u001b[39m.\u001b[39mkeys()))\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch_geometric/nn/conv/hetero_conv.py:138\u001b[0m, in \u001b[0;36mHeteroConv.forward\u001b[0;34m(self, x_dict, edge_index_dict, *args_dict, **kwargs_dict)\u001b[0m\n\u001b[1;32m    136\u001b[0m         out \u001b[39m=\u001b[39m conv(x_dict[src], edge_index, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    137\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m         out \u001b[39m=\u001b[39m conv((x_dict[src], x_dict[dst]), edge_index, \u001b[39m*\u001b[39;49margs,\n\u001b[1;32m    139\u001b[0m                    \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     out_dict[dst]\u001b[39m.\u001b[39mappend(out)\n\u001b[1;32m    143\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m out_dict\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got multiple values for argument 'x_0'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.nn.conv import HeteroConv, GCNConv, SAGEConv, GATConv, FAConv\n",
    "# 定义输入维度和输出维度\n",
    "in_channels = {'paper': 128, 'author': 64}\n",
    "out_channels = 32\n",
    "x_dict = {'paper': torch.randn(4, 128), 'author': torch.randn(2, 64)}\n",
    "edge_index_dict = {\n",
    "    ('paper', 'cites', 'author'): torch.tensor([[0, 3], [0, 1]], dtype=torch.long),\n",
    "    ('author', 'writes', 'paper'): torch.tensor([[0, 1], [0, 1]], dtype=torch.long),\n",
    "    ('paper', 'written-by', 'author'): torch.tensor([[0, 1], [0, 1]], dtype=torch.long),\n",
    "}\n",
    "edge_weight_dict = {\n",
    "    ('paper', 'cites', 'author'): torch.tensor([0, 3], dtype=torch.long),\n",
    "    ('author', 'writes', 'paper'): torch.tensor([0, 1], dtype=torch.long),\n",
    "    ('paper', 'written-by', 'author'): torch.tensor([0, 1], dtype=torch.long),\n",
    "\n",
    "}\n",
    "hetero_conv = HeteroConv({\n",
    "    ('paper', 'cites', 'paper'): FAConv(-1, 64, add_self_loops=False),\n",
    "    ('author', 'writes', 'paper'): FAConv(-1, 64, add_self_loops=False),\n",
    "    ('paper', 'written-by', 'author'): FAConv(-1, 64, add_self_loops=False),\n",
    "}, aggr='sum')\n",
    "x_0_dict = {'paper': torch.randn(4, 128), 'author': torch.randn(2, 64)}\n",
    "\n",
    "out_dict = hetero_conv(x_0_dict=x_0_dict, x_dict=x_dict, edge_index_dict=edge_index_dict, edge_weight_dict=edge_weight_dict)\n",
    "\n",
    "print(list(out_dict.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.7007,  1.6002,  2.9825, -0.6864, -0.2405, -0.8107,  1.5763,  0.5252,\n",
       "           0.7365, -0.7724,  1.1531,  0.3971,  1.1000, -0.7522, -0.4955,  2.8929,\n",
       "          -2.6619,  1.6977,  0.0550,  0.1267, -0.3410, -0.6532, -4.0965,  1.4468,\n",
       "           0.8980,  0.1317, -0.1237, -2.5562,  0.9428, -1.0318,  0.3130, -2.8104,\n",
       "           0.8268,  1.0260,  0.4795,  1.0135, -1.9389, -1.2904, -0.2765, -0.1149,\n",
       "           2.1586, -1.8168,  1.0881, -1.9041,  0.2287,  0.6294, -1.4344, -0.7096,\n",
       "          -0.2209, -0.6772, -0.0328, -0.0053,  0.9681, -0.6699, -0.8222, -0.8622,\n",
       "           0.3187, -0.9926, -2.4349, -1.4375, -1.9346, -0.3260, -1.8784, -0.6747],\n",
       "         [-0.2787,  0.7657,  0.7526,  1.1944,  0.0223, -0.9298,  1.5758,  0.4966,\n",
       "           1.0278, -0.0936, -0.6949, -0.6083,  0.0588, -0.3649, -0.5122, -0.2598,\n",
       "           1.2345,  0.5134,  0.5859, -0.9394,  0.4413, -1.6010, -0.9497,  0.7665,\n",
       "           0.9339,  0.8714, -1.2193, -1.1022,  0.1370, -1.1986, -0.4904, -0.9776,\n",
       "          -0.8059,  0.3061, -0.4502,  0.4556,  0.0073, -0.4293, -0.5593, -1.1504,\n",
       "          -0.6107, -0.2882,  0.6188, -1.9265,  0.1939,  1.7305,  0.5055, -1.8182,\n",
       "          -0.2975, -0.3262,  0.1170, -1.1431, -1.0042,  0.9170, -0.6580,  0.7518,\n",
       "          -0.5772, -1.1101,  1.8619, -1.3656, -0.1395, -1.0558, -0.6980,  0.9357]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[ 0.4629, -0.0405,  1.0216, -0.4095, -1.2411, -0.4327, -1.3833, -0.7942,\n",
       "          -1.8164, -0.1679, -0.2444, -0.3925, -0.3669, -1.0746, -1.7415,  0.5680,\n",
       "           0.7673,  1.3480, -0.9370, -0.2217,  1.4824,  0.5167, -2.1338,  0.3929,\n",
       "           0.5112, -0.8639, -0.2069, -0.9712, -1.0259, -0.9207, -1.2167, -0.4327,\n",
       "          -0.6210, -0.4549, -0.3896,  0.2398, -0.1795, -1.1502,  0.1923,  0.8926,\n",
       "          -1.0519,  0.0279,  0.2010,  0.4772, -0.7508,  1.2375, -0.8840, -0.3889,\n",
       "           0.1315,  0.2361,  0.0132, -1.5236, -1.3621,  1.0709, -1.3684,  0.6782,\n",
       "           0.9986,  0.3469,  1.0424, -1.1748, -1.3808,  0.9273, -0.5100, -1.3326],\n",
       "         [ 1.8668,  0.3396, -0.6157, -0.9188,  0.2072, -1.5617, -0.9730, -0.6048,\n",
       "          -2.0436,  0.7468, -1.6025,  0.7429, -0.1998, -0.3945,  1.6565,  0.3121,\n",
       "          -1.4057,  0.0934,  1.0871, -1.3950,  0.4877, -0.9153, -0.3729,  0.6753,\n",
       "           1.1508, -0.3583, -0.2797,  2.0748, -1.1638, -1.3575,  0.6521,  0.0838,\n",
       "          -1.6557, -0.5907, -0.1600,  1.4900,  0.5835, -1.1629, -0.7925,  0.6066,\n",
       "           0.3568,  0.7158, -0.9608, -0.0055, -0.2412,  0.9565,  0.7387, -0.2240,\n",
       "           0.6842, -0.5598, -1.0789,  0.9913,  0.8534, -0.2895, -0.5768, -0.8953,\n",
       "          -0.4574, -1.8157, -0.6814,  1.0062, -1.2264, -0.3148, -0.5459,  0.1019]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dict['author'], x_dict['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'add_self_loops' attribute set to 'True' on module 'FAConv(128, eps=32)' for use with edge type(s) '[('paper', 'cites', 'author')]'. This will lead to incorrect message passing results.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/notebooks/pytorch_timeseries/notebooks/05_han_conv.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B251-internal-yww-jupyter/notebooks/pytorch_timeseries/notebooks/05_han_conv.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m data_written_by_author \u001b[39m=\u001b[39m Data(edge_index\u001b[39m=\u001b[39medge_index_written_by_author, edge_attr\u001b[39m=\u001b[39medge_weight_dict[(\u001b[39m'\u001b[39m\u001b[39mpaper\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwritten-by\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mauthor\u001b[39m\u001b[39m'\u001b[39m)])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B251-internal-yww-jupyter/notebooks/pytorch_timeseries/notebooks/05_han_conv.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# Define the HeteroConv layer\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B251-internal-yww-jupyter/notebooks/pytorch_timeseries/notebooks/05_han_conv.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m hetero_conv \u001b[39m=\u001b[39m HeteroConv({\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B251-internal-yww-jupyter/notebooks/pytorch_timeseries/notebooks/05_han_conv.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m     (\u001b[39m'\u001b[39;49m\u001b[39mpaper\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcites\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mauthor\u001b[39;49m\u001b[39m'\u001b[39;49m): FAConv(in_channels[\u001b[39m'\u001b[39;49m\u001b[39mpaper\u001b[39;49m\u001b[39m'\u001b[39;49m], out_channels, aggr\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B251-internal-yww-jupyter/notebooks/pytorch_timeseries/notebooks/05_han_conv.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m     (\u001b[39m'\u001b[39;49m\u001b[39mauthor\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mwrites\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mpaper\u001b[39;49m\u001b[39m'\u001b[39;49m): FAConv(in_channels[\u001b[39m'\u001b[39;49m\u001b[39mauthor\u001b[39;49m\u001b[39m'\u001b[39;49m], out_channels, aggr\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B251-internal-yww-jupyter/notebooks/pytorch_timeseries/notebooks/05_han_conv.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     (\u001b[39m'\u001b[39;49m\u001b[39mpaper\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mwritten-by\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mauthor\u001b[39;49m\u001b[39m'\u001b[39;49m): FAConv(in_channels[\u001b[39m'\u001b[39;49m\u001b[39mpaper\u001b[39;49m\u001b[39m'\u001b[39;49m], out_channels, aggr\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B251-internal-yww-jupyter/notebooks/pytorch_timeseries/notebooks/05_han_conv.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m })\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B251-internal-yww-jupyter/notebooks/pytorch_timeseries/notebooks/05_han_conv.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B251-internal-yww-jupyter/notebooks/pytorch_timeseries/notebooks/05_han_conv.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m out_dict \u001b[39m=\u001b[39m hetero_conv(x_dict, edge_index_dict, edge_weight_dict)\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch_geometric/nn/conv/hetero_conv.py:57\u001b[0m, in \u001b[0;36mHeteroConv.__init__\u001b[0;34m(self, convs, aggr)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m     56\u001b[0m \u001b[39mfor\u001b[39;00m edge_type, module \u001b[39min\u001b[39;00m convs\u001b[39m.\u001b[39mitems():\n\u001b[0;32m---> 57\u001b[0m     check_add_self_loops(module, [edge_type])\n\u001b[1;32m     59\u001b[0m src_node_types \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m([key[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m convs\u001b[39m.\u001b[39mkeys()])\n\u001b[1;32m     60\u001b[0m dst_node_types \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m([key[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m convs\u001b[39m.\u001b[39mkeys()])\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch_geometric/utils/hetero.py:54\u001b[0m, in \u001b[0;36mcheck_add_self_loops\u001b[0;34m(module, edge_types)\u001b[0m\n\u001b[1;32m     52\u001b[0m is_bipartite \u001b[39m=\u001b[39m \u001b[39many\u001b[39m([key[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m key[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m edge_types])\n\u001b[1;32m     53\u001b[0m \u001b[39mif\u001b[39;00m is_bipartite \u001b[39mand\u001b[39;00m \u001b[39mgetattr\u001b[39m(module, \u001b[39m'\u001b[39m\u001b[39madd_self_loops\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     55\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39madd_self_loops\u001b[39m\u001b[39m'\u001b[39m\u001b[39m attribute set to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mTrue\u001b[39m\u001b[39m'\u001b[39m\u001b[39m on module \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodule\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfor use with edge type(s) \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00medge_types\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. This will lead to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mincorrect message passing results.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: 'add_self_loops' attribute set to 'True' on module 'FAConv(128, eps=32)' for use with edge type(s) '[('paper', 'cites', 'author')]'. This will lead to incorrect message passing results."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.nn.conv import HeteroConv, FAConv\n",
    "\n",
    "# Define input dimensions and output dimensions\n",
    "in_channels = {'paper': 128, 'author': 64}\n",
    "out_channels = 32\n",
    "\n",
    "x_dict = {'paper': torch.randn(4, 128), 'author': torch.randn(2, 64)}\n",
    "edge_index_dict = {\n",
    "    ('paper', 'cites', 'author'): torch.tensor([[0, 3], [0, 1]], dtype=torch.long),\n",
    "    ('author', 'writes', 'paper'): torch.tensor([[0, 1], [0, 1]], dtype=torch.long),\n",
    "    ('paper', 'written-by', 'author'): torch.tensor([[0, 1], [0, 1]], dtype=torch.long),\n",
    "}\n",
    "\n",
    "# Define the HeteroConv layer\n",
    "hetero_conv = HeteroConv({\n",
    "    ('paper', 'cites', 'author'): FAConv(in_channels['paper'], out_channels, aggr='mean', add_self_loops=False),\n",
    "    ('author', 'writes', 'paper'): FAConv(in_channels['author'], out_channels, aggr='mean', add_self_loops=False),\n",
    "    ('paper', 'written-by', 'author'): FAConv(in_channels['paper'], out_channels, aggr='mean', add_self_loops=False),\n",
    "})\n",
    "\n",
    "# Forward pass\n",
    "out_dict = hetero_conv(x_dict, edge_index_dict)\n",
    "\n",
    "print(list(out_dict.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['author'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
