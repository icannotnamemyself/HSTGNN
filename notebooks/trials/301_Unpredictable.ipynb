{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/notebooks/pytorch_timeseries')\n",
    "\n",
    "import datetime\n",
    "from enum import Enum\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import signal\n",
    "import threading\n",
    "import time\n",
    "import hashlib\n",
    "from prettytable import PrettyTable\n",
    "import sys\n",
    "####\n",
    "from typing import Dict, List, Type, Union\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchmetrics import MeanSquaredError, MetricCollection, MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from torch_timeseries.data.scaler import *\n",
    "from torch_timeseries.datasets import *\n",
    "from torch_timeseries.experiments.experiment import Experiment\n",
    "\n",
    "from torch_timeseries.datasets.dataset import TimeSeriesDataset\n",
    "from torch_timeseries.datasets.splitter import SequenceRandomSplitter, SequenceSplitter\n",
    "from torch_timeseries.datasets.dataloader import (\n",
    "    ChunkSequenceTimefeatureDataLoader,\n",
    "    DDPChunkSequenceTimefeatureDataLoader,\n",
    ")\n",
    "from torch_timeseries.datasets.wrapper import MultiStepTimeFeatureSet\n",
    "from torch_timeseries.models.Informer import Informer\n",
    "from torch.nn import MSELoss, L1Loss\n",
    "\n",
    "from torch.optim import Optimizer, Adam\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, Subset\n",
    "\n",
    "from torch.nn import DataParallel\n",
    "import torch.nn as nn\n",
    "from dataclasses import asdict,dataclass\n",
    "\n",
    "from torch_timeseries.nn.metric import R2, Corr, TrendAcc,RMSE, compute_corr, compute_r2\n",
    "from torch_timeseries.metrics.masked_mape import MaskedMAPE\n",
    "from torch_timeseries.utils.early_stopping import EarlyStopping\n",
    "import json\n",
    "import codecs\n",
    "\n",
    "import copy\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from class_resolver.contrib.torch import activation_resolver\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.nn import FAConv,HeteroConv\n",
    "from torch_geometric.nn import HeteroConv, GCNConv, SAGEConv, GATConv, Linear\n",
    "\n",
    "\n",
    "from torch_timeseries.layers.tcn_output8 import TCNOuputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "\n",
    "from torch_timeseries.models import NLinear\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len, num_features, device, individual=False, normalization=True):\n",
    "        super(Model, self).__init__()\n",
    "        # inputs:\n",
    "        # batch_x: (B, N, T)\n",
    "        \n",
    "        \n",
    "        hidden_dim = 16\n",
    "        self.num_features = num_features\n",
    "        self.normalization = normalization\n",
    "        self.linears = nn.ModuleList()\n",
    "        \n",
    "        for i in range(num_features):\n",
    "            self.linears.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(seq_len, hidden_dim),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_dim, pred_len),\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # batch_x: (B, N, T)\n",
    "        # out: (B, N, O)\n",
    "        if self.normalization:\n",
    "            seq_last = x[:,:,-1:].detach()\n",
    "            x = x - seq_last\n",
    "\n",
    "        # 计算最后一个维度的均值和标准差\n",
    "        # mean = x.mean(dim=2, keepdim=True).detach()\n",
    "        # std = x.std(dim=2, keepdim=True)\n",
    "\n",
    "        # # 标准化处理：最后一个维度减去均值，然后除以标准差\n",
    "        # x = (x - mean) / std\n",
    "\n",
    "        xs = []\n",
    "        for i in range(self.num_features):\n",
    "            xs.append(self.linears[i](x[:, i, :])) # x[:, i, :] =  \n",
    "        x = torch.stack(xs, dim=1)\n",
    "        \n",
    "        if self.normalization:\n",
    "            x = x + seq_last\n",
    "        # x = x + mean\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "@dataclass\n",
    "class ModelExperiment(Experiment):\n",
    "    normalization : bool = True\n",
    "    def _process_model1_train(self, batch_x, batch_y, batch_x_date_enc, batch_y_date_enc):\n",
    "        # inputs:\n",
    "        # batch_x: (B, T, N)\n",
    "        # batch_y: (B, O, N)\n",
    "        # ouputs:\n",
    "        # - pred: (B, N)/(B, O, N)\n",
    "        # - label: (B, N)/(B, O, N)\n",
    "        batch_size = batch_x.size(0)\n",
    "        batch_x = batch_x.to(self.device, dtype=torch.float32)\n",
    "        batch_y = batch_y.to(self.device, dtype=torch.float32)\n",
    "        batch_x_date_enc = batch_x_date_enc.to(self.device).float()\n",
    "        batch_y_date_enc = batch_y_date_enc.to(self.device).float()\n",
    "        \n",
    "        # print(batch_x.shape, self.model1.num)\n",
    "        batch_x = batch_x.transpose(1,2)\n",
    "        \n",
    "        \n",
    "        prior_y = self.model1(batch_x)\n",
    "        # batch_x = batch_x\n",
    "        # outputs = self.model.inference_predict(batch_x)  # torch.Size([batch_size, num_nodes])\n",
    "        # single step prediction\n",
    "        return prior_y, batch_y.transpose(1,2)\n",
    "\n",
    "    def _process_model2_train(self, batch_x, batch_y, prior_y, batch_x_date_enc, batch_y_date_enc):\n",
    "        # inputs:\n",
    "        # prior_y: (B, N, O)\n",
    "        # ouputs:\n",
    "        # - pred: (B, N)/(B, O, N)\n",
    "        # - label: (B, N)/(B, O, N)\n",
    "        y = self.model2(prior_y)  # torch.Size([batch_size, num_nodes])\n",
    "        # single step prediction\n",
    "        return y\n",
    "    def count_parameters(self, print_fun):\n",
    "        total_params = 0\n",
    "        for name, parameter in self.model1.named_parameters():\n",
    "            if not parameter.requires_grad:\n",
    "                continue\n",
    "            params = parameter.numel()\n",
    "            total_params += params\n",
    "            \n",
    "        for name, parameter in self.model2.named_parameters():\n",
    "            if not parameter.requires_grad:\n",
    "                continue\n",
    "            params = parameter.numel()\n",
    "            total_params += params\n",
    "        print_fun(f\"Total Trainable Params: {total_params}\")\n",
    "        return total_params\n",
    "    \n",
    "\n",
    "\n",
    "    def _evaluate(self, dataloader):\n",
    "        self.model1.eval()\n",
    "        self.model2.eval()\n",
    "        self.metrics.reset()\n",
    "        \n",
    "        length = 0\n",
    "        if dataloader is self.train_loader:\n",
    "            length = self.dataloader.train_size\n",
    "        elif dataloader is self.val_loader:\n",
    "            length = self.dataloader.val_size\n",
    "        elif dataloader is self.test_loader:\n",
    "            length = self.dataloader.test_size\n",
    "\n",
    "        # y_truths = []\n",
    "        # y_preds = []\n",
    "        with torch.no_grad():\n",
    "            with tqdm(total=length) as progress_bar:\n",
    "                for batch_x, batch_y,batch_origin_y, batch_x_date_enc, batch_y_date_enc in dataloader:\n",
    "                    batch_size = batch_x.size(0)\n",
    "                    prior_y , truths = self._process_model1_train(\n",
    "                        batch_x, batch_y, batch_x_date_enc, batch_y_date_enc\n",
    "                    )\n",
    "                    preds = self._process_model2_train(\n",
    "                        batch_x, batch_y,prior_y.transpose(1,2).detach(), batch_x_date_enc, batch_y_date_enc\n",
    "                    ).transpose(1,2)\n",
    "                    # the result should be the same\n",
    "                    # self.metrics.update(preds.view(batch_size, -1), truths.view(batch_size, -1))\n",
    "                    # import pdb;pdb.set_trace()\n",
    "                    batch_origin_y = batch_origin_y.to(self.device)\n",
    "                    if self.invtrans_loss:\n",
    "                        preds = self.scaler.inverse_transform(preds)\n",
    "                        truths = batch_origin_y\n",
    "\n",
    "                    if self.pred_len == 1:\n",
    "                        self.metrics.update(prior_y.view(batch_size, -1), truths.view(batch_size, -1))\n",
    "                    else:\n",
    "                        self.metrics.update(prior_y.contiguous(), truths.contiguous())\n",
    "\n",
    "                    progress_bar.update(batch_x.shape[0])\n",
    "\n",
    "            result = {\n",
    "                name: float(metric.compute()) for name, metric in self.metrics.items()\n",
    "            }\n",
    "        return result\n",
    "\n",
    "\n",
    "    def _init_model(self):\n",
    "        \n",
    "        self.model1 = Model(\n",
    "            seq_len=self.windows,\n",
    "            pred_len=self.pred_len,\n",
    "            num_features=self.dataset.num_features,\n",
    "            device=self.device,\n",
    "            normalization=self.normalization,\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.model2 = Model(\n",
    "            seq_len=self.dataset.num_features,\n",
    "            pred_len=self.dataset.num_features,\n",
    "            num_features=self.pred_len,\n",
    "            device=self.device,\n",
    "             normalization=False\n",
    "        ).to(self.device)\n",
    "        self.model = nn.ModuleDict({\n",
    "            'prior': self.model1,\n",
    "            'post': self.model2,\n",
    "        })\n",
    "\n",
    "        self.loss_func = torch.nn.MSELoss()\n",
    "\n",
    "    def _init_optimizer(self):\n",
    "        self.model1_optim = Adam(\n",
    "            self.model1.parameters(), lr=self.lr, weight_decay=self.l2_weight_decay\n",
    "        )\n",
    "        \n",
    "        self.model2_optim = Adam(\n",
    "            self.model2.parameters(), lr=self.lr, weight_decay=self.l2_weight_decay\n",
    "        )\n",
    "\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            self.model1_optim , T_max=self.epochs\n",
    "        )\n",
    "\n",
    "\n",
    "    def run(self, seed=42) -> Dict[str, float]:\n",
    "        if hasattr(self, \"finished\") and self.finished is True:\n",
    "            print(\"Experiment finished!!!\")\n",
    "            return {}\n",
    "\n",
    "        self._setup_run(seed)\n",
    "        if self._check_run_exist(seed):\n",
    "            self._resume_run(seed)\n",
    "\n",
    "        self._run_print(f\"run : {self.current_run} in seed: {seed}\")\n",
    "        \n",
    "        self.model_parameters_num = self.count_parameters(self._run_print)\n",
    "        self._run_print(\n",
    "            f\"model parameters: {self.model_parameters_num}\"\n",
    "        )\n",
    "        if self._use_wandb():\n",
    "            wandb.run.summary[\"parameters\"] = self.model_parameters_num\n",
    "        # for resumable reproducibility\n",
    "\n",
    "        epoch_time = time.time()\n",
    "        while self.current_epoch < self.epochs:\n",
    "            if self.early_stopper.early_stop is True:\n",
    "                self._run_print(\n",
    "                    f\"loss no decreased for {self.patience} epochs,  early stopping ....\"\n",
    "                )\n",
    "                break\n",
    "\n",
    "            if self._use_wandb():\n",
    "                wandb.run.summary[\"at_epoch\"] = self.current_epoch\n",
    "            # for resumable reproducibility\n",
    "            self.reproducible(seed + self.current_epoch)\n",
    "            train_losses =  self._train()\n",
    "\n",
    "            self._run_print(\n",
    "                \"Epoch: {} cost time: {}\".format(\n",
    "                    self.current_epoch + 1, time.time() - epoch_time\n",
    "                )\n",
    "            )\n",
    "            self._run_print(\n",
    "                f\"Traininng loss : {np.mean(train_losses)}\"\n",
    "            )\n",
    "\n",
    "            # self._run_print(f\"Val on train....\")\n",
    "            # trian_val_result = self._evaluate(self.train_loader)\n",
    "            # self._run_print(f\"Val on train result: {trian_val_result}\")\n",
    "            \n",
    "            # evaluate on val set\n",
    "            result = self._val()\n",
    "            # test\n",
    "            test_result = self._test()\n",
    "\n",
    "            self.current_epoch = self.current_epoch + 1\n",
    "            self.early_stopper(result[self.loss_func_type], model=self.model2)\n",
    "            \n",
    "            self._save_run_check_point(seed)\n",
    "\n",
    "            self.scheduler.step()\n",
    "            \n",
    "            # if self._use_wandb():\n",
    "            #     wandb.log(result, step=self.current_epoch)\n",
    "\n",
    "\n",
    "\n",
    "        self._load_best_model()\n",
    "        best_test_result = self._test()\n",
    "        self.run_setuped = False\n",
    "        return best_test_result\n",
    "\n",
    "    def _save_run_check_point(self, seed):\n",
    "        # 检查目录是否存在\n",
    "        if not os.path.exists(self.run_save_dir):\n",
    "            # 如果目录不存在，则创建新目录\n",
    "            os.makedirs(self.run_save_dir)\n",
    "        print(f\"Saving run checkpoint to '{self.run_save_dir}'.\")\n",
    "\n",
    "        self.run_state = {\n",
    "            \"model\": self.model.state_dict(),\n",
    "            \"current_epoch\": self.current_epoch,\n",
    "            # \"optimizer\": self.model_optim.state_dict(),\n",
    "            \"rng_state\": torch.get_rng_state(),\n",
    "            \"early_stopping\": self.early_stopper.get_state(),\n",
    "        }\n",
    "\n",
    "        torch.save(self.run_state, f\"{self.run_checkpoint_filepath}\")\n",
    "        print(\"Run state saved ... \")\n",
    "\n",
    "    def _train(self):\n",
    "        with torch.enable_grad(), tqdm(total=self.train_steps) as progress_bar:\n",
    "            self.model1.train()\n",
    "            self.model2.train()\n",
    "            train_loss = []\n",
    "            for i, (\n",
    "                batch_x,\n",
    "                batch_y,\n",
    "                origin_y,\n",
    "                batch_x_date_enc,\n",
    "                batch_y_date_enc,\n",
    "            ) in enumerate(self.train_loader):\n",
    "                origin_y = origin_y.to(self.device)\n",
    "                self.model1_optim.zero_grad()\n",
    "                self.model2_optim.zero_grad()\n",
    "                prior_y , true = self._process_model1_train(\n",
    "                    batch_x, batch_y, batch_x_date_enc, batch_y_date_enc\n",
    "                )\n",
    "                prior_y.retain_grad()\n",
    "                pred = self._process_model2_train(\n",
    "                    batch_x, batch_y,prior_y.transpose(1,2).detach(), batch_x_date_enc, batch_y_date_enc\n",
    "                ).transpose(1,2)\n",
    "                if self.invtrans_loss:\n",
    "                    prior_y = self.scaler.inverse_transform(prior_y)\n",
    "                    pred = self.scaler.inverse_transform(pred)\n",
    "                    true = origin_y\n",
    "                \n",
    "                loss1 = self.loss_func(prior_y, true)\n",
    "                \n",
    "                loss2 = self.loss_func(pred, true)\n",
    "                \n",
    "                loss1.backward()\n",
    "                loss2.backward()\n",
    "                # if i*self.batch_size >= 1000:\n",
    "                #     import pdb;pdb.set_trace()\n",
    "                \n",
    "                # grad_adjust(prior_y)\n",
    "\n",
    "                # torch.nn.utils.clip_grad_norm_(\n",
    "                #     self.model1.parameters(), self.max_grad_norm\n",
    "                # )\n",
    "                progress_bar.update(batch_x.size(0))\n",
    "                train_loss.append(loss1.item())\n",
    "                progress_bar.set_postfix(\n",
    "                    epoch=self.current_epoch,\n",
    "                    refresh=True,\n",
    "                )\n",
    "\n",
    "                self.model1_optim.step()\n",
    "                self.model2_optim.step()\n",
    "            return train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_adjust(tensor_):\n",
    "    grad = tensor_.grad\n",
    "\n",
    "    # 计算梯度的平均值\n",
    "    abs_grad_mean = abs(grad).mean(1, keepdim=True)\n",
    "    \n",
    "    # ratio = 1 - torch.functional.F.softmax(abs(grad), dim=1)\n",
    "    diff = abs_grad_mean/grad\n",
    "    # 计算每个梯度与平均值的差异比例\n",
    "    # 注意：为避免除以0，可以添加一个小的epsilon值\n",
    "    # epsilon = 0\n",
    "    # weights = (grad - grad_mean) / (grad.std() + epsilon)\n",
    "    \n",
    "    # import pdb;pdb.set_trace()\n",
    "    \n",
    "    # 根据差异调整梯度的大小\n",
    "    # 这里可以根据需要调整比例因子，例如，让差异更加显著\n",
    "    adjusted_grad = grad * diff\n",
    "    tensor_.grad = adjusted_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train steps: 1953\n",
      "val steps: 513\n",
      "test steps: 226\n",
      "torch.get_default_dtype() torch.float32\n",
      "Creating running results saving dir: './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "run : 0 in seed: 3\n",
      "Total Trainable Params: 722\n",
      "model parameters: 722\n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 586.65it/s, epoch=0] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost time: 3.335577964782715\n",
      "Traininng loss : 0.08210194200998353\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 158.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999981741681089, 'mae': 0.23408232629299164, 'mse': 0.05479474365711212, 'r2': -3.323676586151123, 'r2_weighted': -3.323676586151123}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 90.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999956208953753, 'mae': 0.2328750342130661, 'mse': 0.05423080921173096, 'r2': -25.177156448364258, 'r2_weighted': -25.177156448364258}\n",
      "Validation loss decreased (inf --> 0.054795).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 557.62it/s, epoch=1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 cost time: 12.62612771987915\n",
      "Traininng loss : 0.048435354845658425\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:02<00:00, 186.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999982438214263, 'mae': 0.18088117241859436, 'mse': 0.03271801024675369, 'r2': -1.5816729068756104, 'r2_weighted': -1.5816729068756104}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 105.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999955308092704, 'mae': 0.18048469722270966, 'mse': 0.03257473185658455, 'r2': -14.723790168762207, 'r2_weighted': -14.723790168762207}\n",
      "Validation loss decreased (0.054795 --> 0.032718).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:04<00:00, 487.53it/s, epoch=2] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 cost time: 21.55233097076416\n",
      "Traininng loss : 0.02674412165558146\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:02<00:00, 192.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999982888624355, 'mae': 0.13671191036701202, 'mse': 0.018690159544348717, 'r2': -0.47478020191192627, 'r2_weighted': -0.47478020191192627}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 87.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.999995673434142, 'mae': 0.13703185319900513, 'mse': 0.01877773180603981, 'r2': -8.063992500305176, 'r2_weighted': -8.063992500305176}\n",
      "Validation loss decreased (0.032718 --> 0.018690).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 550.96it/s, epoch=3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 cost time: 30.3757963180542\n",
      "Traininng loss : 0.013312761055966538\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 159.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999981937993828, 'mae': 0.09738916903734207, 'mse': 0.009484782814979553, 'r2': 0.251586377620697, 'r2_weighted': 0.251586377620697}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 87.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999957091650877, 'mae': 0.09833559393882751, 'mse': 0.009669902734458447, 'r2': -3.6676526069641113, 'r2_weighted': -3.6676526069641113}\n",
      "Validation loss decreased (0.018690 --> 0.009485).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 536.96it/s, epoch=4] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 cost time: 39.886497020721436\n",
      "Traininng loss : 0.005523001895316185\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 143.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999982286140996, 'mae': 0.06571672856807709, 'mse': 0.004319010302424431, 'r2': 0.6592007875442505, 'r2_weighted': 0.6592007875442505}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 91.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999955834029948, 'mae': 0.0671856701374054, 'mse': 0.004513951018452644, 'r2': -1.1788794994354248, 'r2_weighted': -1.1788794994354248}\n",
      "Validation loss decreased (0.009485 --> 0.004319).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 524.44it/s, epoch=5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 cost time: 49.70011758804321\n",
      "Traininng loss : 0.0020845494056571153\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 144.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999982098335882, 'mae': 0.04449763149023056, 'mse': 0.001980513334274292, 'r2': 0.8437240719795227, 'r2_weighted': 0.8437240719795227}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 94.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999954974957405, 'mae': 0.04627953842282295, 'mse': 0.002141849836334586, 'r2': -0.03386878967285156, 'r2_weighted': -0.03386878967285156}\n",
      "Validation loss decreased (0.004319 --> 0.001981).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 506.84it/s, epoch=6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 cost time: 59.53657102584839\n",
      "Traininng loss : 0.0009834728862774828\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:02<00:00, 174.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999982771899835, 'mae': 0.03258715942502022, 'mse': 0.0010624617571011186, 'r2': 0.9161645770072937, 'r2_weighted': 0.9161645770072937}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 86.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999956247709414, 'mae': 0.03448819741606712, 'mse': 0.0011894971830770373, 'r2': 0.4258309006690979, 'r2_weighted': 0.4258309006690979}\n",
      "Validation loss decreased (0.001981 --> 0.001062).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:04<00:00, 469.01it/s, epoch=7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 cost time: 69.2760751247406\n",
      "Traininng loss : 0.0006358164199252403\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 169.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999982268649515, 'mae': 0.026258571073412895, 'mse': 0.0006900464650243521, 'r2': 0.9455506801605225, 'r2_weighted': 0.9455506801605225}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 87.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999955285141292, 'mae': 0.028150586411356926, 'mse': 0.0007925165700726211, 'r2': 0.6174530982971191, 'r2_weighted': 0.6174530982971191}\n",
      "Validation loss decreased (0.001062 --> 0.000690).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 523.95it/s, epoch=8] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 cost time: 78.65269088745117\n",
      "Traininng loss : 0.000499525781995016\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:02<00:00, 183.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999982359804409, 'mae': 0.022825587540864944, 'mse': 0.000521504320204258, 'r2': 0.9588497877120972, 'r2_weighted': 0.9588497877120972}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 85.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999954581324395, 'mae': 0.024650925770401955, 'mse': 0.0006077249418012798, 'r2': 0.7066518068313599, 'r2_weighted': 0.7066518068313599}\n",
      "Validation loss decreased (0.000690 --> 0.000522).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 501.40it/s, epoch=9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 cost time: 88.0276780128479\n",
      "Traininng loss : 0.0004086290552344684\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 143.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.999998130477369, 'mae': 0.02046477608382702, 'mse': 0.0004192576452624053, 'r2': 0.9669177532196045, 'r2_weighted': 0.9669177532196045}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 84.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999957186245759, 'mae': 0.022202540189027786, 'mse': 0.0004930041031911969, 'r2': 0.762027382850647, 'r2_weighted': 0.762027382850647}\n",
      "Validation loss decreased (0.000522 --> 0.000419).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:04<00:00, 452.61it/s, epoch=10] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 cost time: 98.66810703277588\n",
      "Traininng loss : 0.00033740781861612754\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 141.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999982639023192, 'mae': 0.01847291737794876, 'mse': 0.0003416538820602, 'r2': 0.9730411767959595, 'r2_weighted': 0.9730411767959595}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 77.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999956318095533, 'mae': 0.0201208908110857, 'mse': 0.00040489656385034323, 'r2': 0.8045568466186523, 'r2_weighted': 0.8045568466186523}\n",
      "Validation loss decreased (0.000419 --> 0.000342).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 518.18it/s, epoch=11] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 cost time: 109.02230978012085\n",
      "Traininng loss : 0.00027766328123341794\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 138.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999981217802335, 'mae': 0.016833633184432983, 'mse': 0.0002837286447174847, 'r2': 0.9776118993759155, 'r2_weighted': 0.9776118993759155}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 89.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999956073031118, 'mae': 0.018381327390670776, 'mse': 0.00033791392343118787, 'r2': 0.8368892669677734, 'r2_weighted': 0.8368892669677734}\n",
      "Validation loss decreased (0.000342 --> 0.000284).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:04<00:00, 484.12it/s, epoch=12] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 cost time: 119.3306028842926\n",
      "Traininng loss : 0.00022719911927167907\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 146.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999982540192878, 'mae': 0.015304053202271461, 'mse': 0.00023452963796444237, 'r2': 0.9814940094947815, 'r2_weighted': 0.9814940094947815}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 78.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999955883576619, 'mae': 0.016758281737565994, 'mse': 0.0002808759454637766, 'r2': 0.8644214868545532, 'r2_weighted': 0.8644214868545532}\n",
      "Validation loss decreased (0.000284 --> 0.000235).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 536.14it/s, epoch=13] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 cost time: 129.42688393592834\n",
      "Traininng loss : 0.00018557110935592304\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 137.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999982389532689, 'mae': 0.013972398824989796, 'mse': 0.00019550436991266906, 'r2': 0.9845733642578125, 'r2_weighted': 0.9845733642578125}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 94.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999956012846146, 'mae': 0.015333367511630058, 'mse': 0.000235143699683249, 'r2': 0.886496365070343, 'r2_weighted': 0.886496365070343}\n",
      "Validation loss decreased (0.000235 --> 0.000196).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 497.26it/s, epoch=14] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 cost time: 139.54763889312744\n",
      "Traininng loss : 0.0001502562205249917\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 143.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.99999821675252, 'mae': 0.012428955174982548, 'mse': 0.00015472256927751005, 'r2': 0.9877913594245911, 'r2_weighted': 0.9877913594245911}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 100.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999955692307453, 'mae': 0.013706435449421406, 'mse': 0.0001878940820461139, 'r2': 0.9093037247657776, 'r2_weighted': 0.9093037247657776}\n",
      "Validation loss decreased (0.000196 --> 0.000155).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 510.62it/s, epoch=15] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 cost time: 149.22716617584229\n",
      "Traininng loss : 0.00011751706229152924\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 136.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.999998280803618, 'mae': 0.011167766526341438, 'mse': 0.00012493145186454058, 'r2': 0.9901420474052429, 'r2_weighted': 0.9901420474052429}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 98.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.999995625539823, 'mae': 0.012360687367618084, 'mse': 0.00015281079686246812, 'r2': 0.9262383580207825, 'r2_weighted': 0.9262383580207825}\n",
      "Validation loss decreased (0.000155 --> 0.000125).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:04<00:00, 456.52it/s, epoch=16] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 cost time: 159.62754821777344\n",
      "Traininng loss : 9.238398257777237e-05\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 159.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999982452701983, 'mae': 0.009945731610059738, 'mse': 9.910160588333383e-05, 'r2': 0.9921802282333374, 'r2_weighted': 0.9921802282333374}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 81.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999955626291903, 'mae': 0.01105722039937973, 'mse': 0.00012228313426021487, 'r2': 0.9409740567207336, 'r2_weighted': 0.9409740567207336}\n",
      "Validation loss decreased (0.000125 --> 0.000099).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 492.02it/s, epoch=17] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 cost time: 169.6936674118042\n",
      "Traininng loss : 7.016093334846852e-05\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 160.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999982599318987, 'mae': 0.008775006979703903, 'mse': 7.716114487266168e-05, 'r2': 0.9939114451408386, 'r2_weighted': 0.9939114451408386}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 83.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999956108216588, 'mae': 0.00981115736067295, 'mse': 9.62770645855926e-05, 'r2': 0.9535271525382996, 'r2_weighted': 0.9535271525382996}\n",
      "Validation loss decreased (0.000099 --> 0.000077).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 559.40it/s, epoch=18] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 cost time: 179.144216299057\n",
      "Traininng loss : 4.827693177386179e-05\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 138.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.999998191267687, 'mae': 0.0074167135171592236, 'mse': 5.5149448598967865e-05, 'r2': 0.9956483244895935, 'r2_weighted': 0.9956483244895935}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 74.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999955585680539, 'mae': 0.008390854112803936, 'mse': 7.042255310807377e-05, 'r2': 0.9660071134567261, 'r2_weighted': 0.9660071134567261}\n",
      "Validation loss decreased (0.000077 --> 0.000055).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 536.16it/s, epoch=19] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 cost time: 189.6317479610443\n",
      "Traininng loss : 3.5484768960163964e-05\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 164.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999982791708364, 'mae': 0.006368095055222511, 'mse': 4.0677190554561093e-05, 'r2': 0.9967902898788452, 'r2_weighted': 0.9967902898788452}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 80.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999956422280594, 'mae': 0.007280962076038122, 'mse': 5.302655335981399e-05, 'r2': 0.9744041562080383, 'r2_weighted': 0.9744041562080383}\n",
      "Validation loss decreased (0.000055 --> 0.000041).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 560.42it/s, epoch=20] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 cost time: 199.0790560245514\n",
      "Traininng loss : 2.247552175328066e-05\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 165.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999981412622804, 'mae': 0.005413125269114971, 'mse': 2.941065758932382e-05, 'r2': 0.9976792931556702, 'r2_weighted': 0.9976792931556702}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 95.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999955665553789, 'mae': 0.006265921983867884, 'mse': 3.927412035409361e-05, 'r2': 0.9810424447059631, 'r2_weighted': 0.9810424447059631}\n",
      "Validation loss decreased (0.000041 --> 0.000029).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 510.90it/s, epoch=21] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 cost time: 208.39808869361877\n",
      "Traininng loss : 1.9502580669488394e-05\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 170.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999981456569785, 'mae': 0.004715208429843187, 'mse': 2.232893166365102e-05, 'r2': 0.9982380867004395, 'r2_weighted': 0.9982380867004395}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 94.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999955906782444, 'mae': 0.005515321157872677, 'mse': 3.042962634935975e-05, 'r2': 0.9853116273880005, 'r2_weighted': 0.9853116273880005}\n",
      "Validation loss decreased (0.000029 --> 0.000022).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:04<00:00, 474.84it/s, epoch=22] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 cost time: 217.93799257278442\n",
      "Traininng loss : 2.9985746172931086e-05\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 158.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999981875325998, 'mae': 0.004062563180923462, 'mse': 1.6589498045505024e-05, 'r2': 0.9986909627914429, 'r2_weighted': 0.9986909627914429}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 87.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999955995247767, 'mae': 0.004816687665879726, 'mse': 2.3210124709294178e-05, 'r2': 0.9887964725494385, 'r2_weighted': 0.9887964725494385}\n",
      "Validation loss decreased (0.000022 --> 0.000017).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:04<00:00, 472.01it/s, epoch=23] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 cost time: 227.96266961097717\n",
      "Traininng loss : 1.4375305135393817e-05\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 155.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999982138839667, 'mae': 0.0035811318084597588, 'mse': 1.2898125532956328e-05, 'r2': 0.9989822506904602, 'r2_weighted': 0.9989822506904602}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 93.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.99999549021759, 'mae': 0.004282515961676836, 'mse': 1.8348284356761724e-05, 'r2': 0.9911432862281799, 'r2_weighted': 0.9911432862281799}\n",
      "Validation loss decreased (0.000017 --> 0.000013).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 497.40it/s, epoch=24] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 cost time: 237.65390038490295\n",
      "Traininng loss : 8.93517958208958e-06\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 156.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999981878618878, 'mae': 0.003223160281777382, 'mse': 1.0452310561959166e-05, 'r2': 0.9991752505302429, 'r2_weighted': 0.9991752505302429}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 91.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999956071132867, 'mae': 0.0038746700156480074, 'mse': 1.5020259525044821e-05, 'r2': 0.9927497506141663, 'r2_weighted': 0.9927497506141663}\n",
      "Validation loss decreased (0.000013 --> 0.000010).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:04<00:00, 466.08it/s, epoch=25] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 cost time: 247.628564119339\n",
      "Traininng loss : 6.986074133408238e-06\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 152.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999981895666503, 'mae': 0.002899467945098877, 'mse': 8.461576726404019e-06, 'r2': 0.9993323087692261, 'r2_weighted': 0.9993323087692261}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 86.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999955389777988, 'mae': 0.003503571031615138, 'mse': 1.22811889013974e-05, 'r2': 0.994071900844574, 'r2_weighted': 0.994071900844574}\n",
      "Validation loss decreased (0.000010 --> 0.000008).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 509.87it/s, epoch=26] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 cost time: 257.5293698310852\n",
      "Traininng loss : 5.7161469332215585e-06\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 155.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999982345078701, 'mae': 0.002578043146058917, 'mse': 6.6932093432114925e-06, 'r2': 0.9994718432426453, 'r2_weighted': 0.9994718432426453}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 90.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999955734062859, 'mae': 0.0031374888494610786, 'mse': 9.849131856753957e-06, 'r2': 0.9952458143234253, 'r2_weighted': 0.9952458143234253}\n",
      "Validation loss decreased (0.000008 --> 0.000007).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 490.49it/s, epoch=27] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 cost time: 267.3480615615845\n",
      "Traininng loss : 4.688435465581161e-06\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 142.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999982916250334, 'mae': 0.002375546842813492, 'mse': 5.683289145963499e-06, 'r2': 0.99955153465271, 'r2_weighted': 0.99955153465271}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 94.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999955134425214, 'mae': 0.0028924820944666862, 'mse': 8.370971045223996e-06, 'r2': 0.9959593415260315, 'r2_weighted': 0.9959593415260315}\n",
      "Validation loss decreased (0.000007 --> 0.000006).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 544.83it/s, epoch=28] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 cost time: 277.0006320476532\n",
      "Traininng loss : 3.967887522549063e-06\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 143.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999982021645473, 'mae': 0.0020105023868381977, 'mse': 4.076385721418774e-06, 'r2': 0.999678373336792, 'r2_weighted': 0.999678373336792}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 77.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999956513584514, 'mae': 0.0024884301237761974, 'mse': 6.196144568093587e-06, 'r2': 0.9970090985298157, 'r2_weighted': 0.9970090985298157}\n",
      "Validation loss decreased (0.000006 --> 0.000004).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 526.07it/s, epoch=29] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 cost time: 287.27822065353394\n",
      "Traininng loss : 3.422770121352231e-06\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 150.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999982510502272, 'mae': 0.0017300776671618223, 'mse': 3.0224216516216984e-06, 'r2': 0.9997615218162537, 'r2_weighted': 0.9997615218162537}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 84.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999955223825547, 'mae': 0.002171511761844158, 'mse': 4.718753189081326e-06, 'r2': 0.9977222681045532, 'r2_weighted': 0.9977222681045532}\n",
      "Validation loss decreased (0.000004 --> 0.000003).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 555.08it/s, epoch=30] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 cost time: 296.9613814353943\n",
      "Traininng loss : 3.137067985625025e-06\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 170.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999982484896103, 'mae': 0.0014706481015309691, 'mse': 2.1878386178286746e-06, 'r2': 0.9998273849487305, 'r2_weighted': 0.9998273849487305}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 74.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999956206413904, 'mae': 0.0018788576126098633, 'mse': 3.5329171623743605e-06, 'r2': 0.9982946515083313, 'r2_weighted': 0.9982946515083313}\n",
      "Validation loss decreased (0.000003 --> 0.000002).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 499.10it/s, epoch=31] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 cost time: 307.00762248039246\n",
      "Traininng loss : 3.047679400202513e-06\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 144.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999983093113572, 'mae': 0.001271924120374024, 'mse': 1.63915228768019e-06, 'r2': 0.9998706579208374, 'r2_weighted': 0.9998706579208374}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 81.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999955426016206, 'mae': 0.0016488780966028571, 'mse': 2.7211945052840747e-06, 'r2': 0.9986864924430847, 'r2_weighted': 0.9986864924430847}\n",
      "Validation loss decreased (0.000002 --> 0.000002).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:04<00:00, 481.27it/s, epoch=32] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 cost time: 317.41121768951416\n",
      "Traininng loss : 2.9982364563558636e-06\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 168.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999982420228655, 'mae': 0.0010526211699470878, 'mse': 1.1261892041147803e-06, 'r2': 0.9999111294746399, 'r2_weighted': 0.9999111294746399}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 79.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999956453994517, 'mae': 0.0014002048410475254, 'mse': 1.962608394023846e-06, 'r2': 0.9990526437759399, 'r2_weighted': 0.9990526437759399}\n",
      "Validation loss decreased (0.000002 --> 0.000001).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:04<00:00, 486.29it/s, epoch=33] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 cost time: 327.36645245552063\n",
      "Traininng loss : 2.9463480516717996e-06\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 166.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999982234916851, 'mae': 0.0008928588940761983, 'mse': 8.126405077746313e-07, 'r2': 0.9999358654022217, 'r2_weighted': 0.9999358654022217}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 86.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999955719289859, 'mae': 0.001213090610690415, 'mse': 1.4733141142642125e-06, 'r2': 0.9992888569831848, 'r2_weighted': 0.9992888569831848}\n",
      "Validation loss decreased (0.000001 --> 0.000001).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 519.71it/s, epoch=34] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 cost time: 336.8347463607788\n",
      "Traininng loss : 3.1575061133170744e-06\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:02<00:00, 172.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999981646325278, 'mae': 0.0007553488831035793, 'mse': 5.836307082063286e-07, 'r2': 0.9999539256095886, 'r2_weighted': 0.9999539256095886}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 90.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999955863639511, 'mae': 0.0010498989140614867, 'mse': 1.1037450349249411e-06, 'r2': 0.9994671940803528, 'r2_weighted': 0.9994671940803528}\n",
      "Validation loss decreased (0.000001 --> 0.000001).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 527.46it/s, epoch=35] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 cost time: 346.0574827194214\n",
      "Traininng loss : 3.105962966218972e-06\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 145.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999982684027451, 'mae': 0.0006472597597166896, 'mse': 4.2988204995708656e-07, 'r2': 0.9999660849571228, 'r2_weighted': 0.9999660849571228}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 75.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999955102924654, 'mae': 0.0009164541261270642, 'mse': 8.411038834310602e-07, 'r2': 0.99959397315979, 'r2_weighted': 0.99959397315979}\n",
      "Validation loss decreased (0.000001 --> 0.000000).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:04<00:00, 480.85it/s, epoch=36] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 cost time: 356.7271101474762\n",
      "Traininng loss : 3.1074234841764426e-06\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:03<00:00, 155.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.9999981933697748, 'mae': 0.000535394239705056, 'mse': 2.957979177153902e-07, 'r2': 0.999976634979248, 'r2_weighted': 0.999976634979248}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:02<00:00, 88.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.9999956369731476, 'mae': 0.0007814785931259394, 'mse': 6.117232942415285e-07, 'r2': 0.9997047185897827, 'r2_weighted': 0.9997047185897827}\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/test3/DummyContinuous/w40h24s1/efda345510cbccce8a1a20acb5f5231b'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:03<00:00, 500.21it/s, epoch=37] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 cost time: 366.54438877105713\n",
      "Traininng loss : 3.089996072863106e-06\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/513 [00:00<?, ?it/s]Exception ignored in: <function _releaseLock at 0x7fe636279af0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/py38/lib/python3.8/logging/__init__.py\", line 227, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <function _releaseLock at 0x7fe636279af0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/py38/lib/python3.8/logging/__init__.py\", line 227, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <function _releaseLock at 0x7fe636279af0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/py38/lib/python3.8/logging/__init__.py\", line 227, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n",
      "  0%|          | 0/513 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 2804953, 2805016, 2805079, 2805142, 2805205, 2805268, 2805331, 2805394, 2805457, 2805520) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/multiprocessing/queues.py:108\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[0;32m--> 108\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m exp \u001b[38;5;241m=\u001b[39m ModelExperiment(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# dataset_type=\"SP500\",\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     model_type \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[85], line 242\u001b[0m, in \u001b[0;36mModelExperiment.run\u001b[0;34m(self, seed)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_print(\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraininng loss : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(train_losses)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    235\u001b[0m )\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# self._run_print(f\"Val on train....\")\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# trian_val_result = self._evaluate(self.train_loader)\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# self._run_print(f\"Val on train result: {trian_val_result}\")\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m# evaluate on val set\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_val\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# test\u001b[39;00m\n\u001b[1;32m    244\u001b[0m test_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test()\n",
      "File \u001b[0;32m/notebooks/pytorch_timeseries/torch_timeseries/experiments/experiment.py:596\u001b[0m, in \u001b[0;36mExperiment._val\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_val\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating .... \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 596\u001b[0m     val_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, metric_value \u001b[38;5;129;01min\u001b[39;00m val_result\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    600\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_wandb():\n",
      "Cell \u001b[0;32mIn[85], line 128\u001b[0m, in \u001b[0;36mModelExperiment._evaluate\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mlength) \u001b[38;5;28;01mas\u001b[39;00m progress_bar:\n\u001b[0;32m--> 128\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m batch_x, batch_y,batch_origin_y, batch_x_date_enc, batch_y_date_enc \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m    129\u001b[0m             batch_size \u001b[38;5;241m=\u001b[39m batch_x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    130\u001b[0m             prior_y , truths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_model1_train(\n\u001b[1;32m    131\u001b[0m                 batch_x, batch_y, batch_x_date_enc, batch_y_date_enc\n\u001b[1;32m    132\u001b[0m             )\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1145\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1144\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(pids_str)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 2804953, 2805016, 2805079, 2805142, 2805205, 2805268, 2805331, 2805394, 2805457, 2805520) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "exp = ModelExperiment(\n",
    "    # dataset_type=\"SP500\",\n",
    "    model_type =\"test3\",\n",
    "    normalization=True,\n",
    "    dataset_type=\"DummyContinuous\",\n",
    "    horizon=24,\n",
    "    pred_len=1,\n",
    "    data_path='/notebooks/pytorch_timeseries/data/',\n",
    "    windows=40,\n",
    "    \n",
    ")\n",
    "\n",
    "exp.run(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/notebooks/pytorch_timeseries/notebooks/trials/201_GP.ipynb Cell 9\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B250-internal-yww-jupyter/notebooks/pytorch_timeseries/notebooks/trials/201_GP.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m hot_encoding_matrix \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meye(feature_number)\u001b[39m.\u001b[39mdetach()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B250-internal-yww-jupyter/notebooks/pytorch_timeseries/notebooks/trials/201_GP.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m temporal_encoding_matrix \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, output_length) \u001b[39m/\u001b[39m output_length \u001b[39m# \u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B250-internal-yww-jupyter/notebooks/pytorch_timeseries/notebooks/trials/201_GP.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m x_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mconcat([hot_encoding_matrix, temporal_encoding_matrix], dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39mdetach()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 1"
     ]
    }
   ],
   "source": [
    "feature_number = 10\n",
    "output_length = 10\n",
    "hot_encoding_matrix = torch.eye(feature_number).detach()\n",
    "temporal_encoding_matrix = torch.arange(0, output_length) / output_length # \n",
    "\n",
    "\n",
    "x_input = torch.concat([hot_encoding_matrix, temporal_encoding_matrix], dim=0).detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_encoding_matrix.unsqueeze(1).repeat(1, feature_number).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe4c84893a0>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAGdCAYAAADaPpOnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzGElEQVR4nO3de3QUZYL//0+HJJ0LSYckJOlACBHBCzCMgnLRUdARiYrXURgdLl+VXVZ0ZRi+anbHn7izZ6Izjoev4nUPohxcYc/hIrM4CqxcBo0KAq6iYtBAAkkICaQ7F9IJSf3+SNKkybWbdCoV3q9z6qS76qnK81Bp++PzPFVlMwzDEAAAgEWEmF0BAAAAfxBeAACApRBeAACApRBeAACApRBeAACApRBeAACApRBeAACApRBeAACApYSaXYHu1tDQoMLCQsXExMhms5ldHQAA0AWGYaiiokKpqakKCem4b6XPhZfCwkKlpaWZXQ0AABCAgoICDR48uMMyfS68xMTESGpsfGxsrMm1AQAAXeF2u5WWlub9Hu9InwsvzUNFsbGxhBcAACymK1M+mLALAAAshfACAAAshfACAAAshfACAAAshfACAAAshfACAAAshfACAAAshfACAAAshfACAAAshfACAAAshfACAAAshfACAAAshfDip89+KtPqL/LNrgYAABesPvdU6WCb+eZnkqThyf01Nj3e5NoAAHDhoeclQAUnT5tdBQAALkiElwAZMsyuAgAAFyTCCwAAsBTCCwAAsBTCCwAAsBTCCwAAsBTCCwAAsBTCCwAAsBTCCwAAsBTCCwAAsBTCS4AM7lEHAIApAg4vO3fu1PTp05WamiqbzaYNGzb4bJ87d65sNpvPMmHChE6Pu3btWl1++eWy2+26/PLLtX79+kCrCAAA+qCAw0tVVZXGjBmjZcuWtVtm2rRpKioq8i4ffPBBh8fMycnRjBkzNGvWLH311VeaNWuW7rvvPn3++eeBVhMAAPQxAT9VOjMzU5mZmR2WsdvtSklJ6fIxly5dqptuuklZWVmSpKysLO3YsUNLly7Ve++9F2hVAQBAHxLUOS/bt29XUlKSRowYoXnz5qmkpKTD8jk5OZo6darPuptvvlmffvppu/t4PB653W6fBQAA9F1BCy+ZmZl699139fHHH+svf/mLdu/erRtuuEEej6fdfYqLi5WcnOyzLjk5WcXFxe3uk52dLYfD4V3S0tK6rQ0AAKD3CXjYqDMzZszwvh41apTGjRun9PR0bdq0SXfffXe7+9lsNp/3hmG0WtdSVlaWFi1a5H3vdrsJMAAA9GFBCy/ncjqdSk9PV25ubrtlUlJSWvWylJSUtOqNaclut8tut3dbPQEAQO/WY/d5KSsrU0FBgZxOZ7tlJk6cqC1btvis27x5syZNmhTs6vmN+7wAAGCOgHteKisrdejQIe/7vLw87d+/X/Hx8YqPj9eSJUt0zz33yOl06vDhw/qXf/kXJSYm6q677vLuM3v2bA0aNEjZ2dmSpMcff1zXXXednn/+ed1xxx16//33tXXrVu3ates8mggAAPqSgMPLnj17NGXKFO/75nknc+bM0Wuvvaavv/5aK1euVHl5uZxOp6ZMmaI1a9YoJibGu09+fr5CQs52/kyaNEmrV6/W73//ez399NMaNmyY1qxZo/HjxwdaTQAA0MfYDKNvDYC43W45HA65XC7FxsZ2+/GHPrVJkvSXe8fonrGDu/34AABciPz5/ubZRgAAwFIILwAAwFIILwAAwFIILwAAwFIILwAAwFIILwHqU5doAQBgIYQXAABgKYQXAABgKYQXAABgKYQXAABgKYQXAABgKYSXAPWxR0IBAGAZhBcAAGAphBcAAGAphBcAAGAphBcAAGAphBcAAGAphBcAAGAphBcAAGAphBcAAGAphBcAAGAphBcAAGAphJcA8XAAAADMQXgBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngJFJcbAQBgCsILAACwFMJLoGxmVwAAgAsT4SVQDBsBAGAKwgsAALAUwgsAALCUgMPLzp07NX36dKWmpspms2nDhg3ebXV1dXryySc1evRoRUdHKzU1VbNnz1ZhYWGHx3z77bdls9laLTU1NYFWEwAA9DEBh5eqqiqNGTNGy5Yta7Wturpae/fu1dNPP629e/dq3bp1+uGHH3T77bd3etzY2FgVFRX5LBEREYFWEwAA9DGhge6YmZmpzMzMNrc5HA5t2bLFZ93LL7+sq6++Wvn5+RoyZEi7x7XZbEpJSQm0WgAAoI/rsTkvLpdLNptNcXFxHZarrKxUenq6Bg8erNtuu0379u3rsLzH45Hb7fZZeoLB5UYAAJiiR8JLTU2NnnrqKd1///2KjY1tt9yll16qt99+Wxs3btR7772niIgIXXPNNcrNzW13n+zsbDkcDu+SlpYWjCYAAIBeIujhpa6uTjNnzlRDQ4NeffXVDstOmDBBv/nNbzRmzBj94he/0H/9139pxIgRevnll9vdJysrSy6Xy7sUFBR0dxMAAEAvEvCcl66oq6vTfffdp7y8PH388ccd9rq0JSQkRFdddVWHPS92u112u/18qwoAACwiaD0vzcElNzdXW7duVUJCgt/HMAxD+/fvl9PpDEINAQCAFQXc81JZWalDhw553+fl5Wn//v2Kj49XamqqfvWrX2nv3r367//+b9XX16u4uFiSFB8fr/DwcEnS7NmzNWjQIGVnZ0uSnn32WU2YMEHDhw+X2+3WSy+9pP379+uVV145nzYCAIA+JODwsmfPHk2ZMsX7ftGiRZKkOXPmaMmSJdq4caMk6ec//7nPftu2bdPkyZMlSfn5+QoJOdv5U15ern/4h39QcXGxHA6HrrjiCu3cuVNXX311oNUMGoOLjQAAMIXNMPrW17Db7ZbD4ZDL5fJ7jk1XDH1qkyTpubtHa+bV7d+vBgAAdJ0/39882yhANpvZNQAA4MJEeAEAAJZCePFDHxthAwDAkggvASLHAABgDsILAACwFMKLH+htAQDAfIQXAABgKYQXAABgKYQXPzBqBACA+QgvASLIAABgDsILAACwFMKLH7hJHQAA5iO8AAAASyG8AAAASyG8+IFBIwAAzEd4AQAAlkJ4AQAAlkJ48QMXGwEAYD7CS4AIMgAAmIPw4geDKbsAAJiO8AIAACyF8AIAACyF8OIH5rkAAGA+wgsAALAUwkuAmLwLAIA5CC8AAMBSCC8AAMBSCC8AAMBSCC9+4GojAADMR3gBAACWQngBAACWQnjxA5dHAwBgPsILAACwFMILAACwlIDDy86dOzV9+nSlpqbKZrNpw4YNPtsNw9CSJUuUmpqqyMhITZ48WQcOHOj0uGvXrtXll18uu92uyy+/XOvXrw+0it2Oq40AADBfwOGlqqpKY8aM0bJly9rc/qc//Ukvvviili1bpt27dyslJUU33XSTKioq2j1mTk6OZsyYoVmzZumrr77SrFmzdN999+nzzz8PtJpBQ5ABAMAcNsM4/69hm82m9evX684775TU2OuSmpqqhQsX6sknn5QkeTweJScn6/nnn9c//uM/tnmcGTNmyO12629/+5t33bRp0zRgwAC99957XaqL2+2Ww+GQy+VSbGzs+TXsHFWeMxr5zEeSpH+/c5R+MyG9W48PAMCFyp/v76DMecnLy1NxcbGmTp3qXWe323X99dfr008/bXe/nJwcn30k6eabb+5wH4/HI7fb7bMEC50tAACYLyjhpbi4WJKUnJzssz45Odm7rb39/N0nOztbDofDu6SlpZ1HzQEAQG8X1KuNbDabz3vDMFqtO999srKy5HK5vEtBQUHgFQYAAL1eaDAOmpKSIqmxJ8XpdHrXl5SUtOpZOXe/c3tZOtvHbrfLbrefZ427phumBwEAgPMUlJ6XjIwMpaSkaMuWLd51tbW12rFjhyZNmtTufhMnTvTZR5I2b97c4T5mIcYAAGCOgHteKisrdejQIe/7vLw87d+/X/Hx8RoyZIgWLlyoP/7xjxo+fLiGDx+uP/7xj4qKitL999/v3Wf27NkaNGiQsrOzJUmPP/64rrvuOj3//PO644479P7772vr1q3atWvXeTQRAAD0JQGHlz179mjKlCne94sWLZIkzZkzR2+//baeeOIJnT59Wo888ohOnTql8ePHa/PmzYqJifHuk5+fr5CQs50/kyZN0urVq/X73/9eTz/9tIYNG6Y1a9Zo/PjxgVazW9HbAgCA+brlPi+9STDv8+KuqdPPlmyWJP3hzlGaxX1eAADoFqbf5wUAACBYCC9+6Ft9VAAAWBPhBQAAWArhBQAAWArhxR8MGwEAYDrCS6CYAAMAgCkILwAAwFIIL34wGDcCAMB0hBcAAGAphBcAAGAphBc/MEcXAADzEV4AAIClEF784NPxYrOZVQ0AAC5ohJdAMYYEAIApCC8AAMBSCC9+MFr2tjBsBACAKQgvgWLYCAAAUxBeAACApRBe/MDVRgAAmI/wAgAALIXwEijmvAAAYArCix/IKwAAmI/wAgAALIXwAgAALIXw4gejxfVGjCABAGAOwgsAALAUwgsAALAUwos/WowVceURAADmILwAAABLIbwAAABLIbz4gZEiAADMR3gJkMGkFwAATEF4AQAAlkJ48QOdLQAAmC+o4WXo0KGy2WytlgULFrRZfvv27W2W//7774NZzYCQYwAAMEdoMA++e/du1dfXe99/8803uummm3Tvvfd2uN/BgwcVGxvrfT9w4MCg1REAAFhLUMPLuaHjueee07Bhw3T99dd3uF9SUpLi4uKCWLPAGPS3AABguh6b81JbW6tVq1bpwQcflM1m67DsFVdcIafTqRtvvFHbtm3rsKzH45Hb7fZZAABA39Vj4WXDhg0qLy/X3Llz2y3jdDr15ptvau3atVq3bp0uueQS3Xjjjdq5c2e7+2RnZ8vhcHiXtLS0INS+NSbvAgBgDpvRQzcsufnmmxUeHq6//vWvfu03ffp02Ww2bdy4sc3tHo9HHo/H+97tdistLU0ul8tn3kx3KCw/rUnPfSxJ+v9uu1wPXpvRrccHAOBC5Xa75XA4uvT9HdQ5L82OHDmirVu3at26dX7vO2HCBK1atard7Xa7XXa7/XyqBwAALKRHho1WrFihpKQk3XrrrX7vu2/fPjmdziDUCgAAWFHQe14aGhq0YsUKzZkzR6Ghvr8uKytLx44d08qVKyVJS5cu1dChQzVy5EjvBN+1a9dq7dq1wa5mlxjtvAYAAD0n6OFl69atys/P14MPPthqW1FRkfLz873va2trtXjxYh07dkyRkZEaOXKkNm3apFtuuSXY1QQAABbRYxN2e4o/E378daz8tK5pmrD79G2X6yEm7AIA0C38+f7m2UZ+aJnz+ljmAwDAMggvAADAUggvfqCzBQAA8xFeAACApRBeAACApRBeAACApRBeAACApRBeAACApRBe/NDyaiOuPAIAwByEFwAAYCmEFwAAYCmEFz8YLZ4lbfBcaQAATEF4AQAAlkJ4AQAAlkJ48QNXGAEAYD7CS4AIMgAAmIPwAgAALIXw4gc6WwAAMB/hBQAAWArhJUD0wgAAYA7Cix8MZukCAGA6wgsAALAUwkuA6IQBAMAchBc/kFcAADAf4QUAAFgK4QUAAFgK4cUPLee5GAwiAQBgCsILAACwFMILAACwFMKLX84OFXGpNAAA5iC8AAAASyG8AAAASyG8+IGhIgAAzEd4AQAAlhLU8LJkyRLZbDafJSUlpcN9duzYobFjxyoiIkIXXXSRXn/99WBWEQAAWExosH/ByJEjtXXrVu/7fv36tVs2Ly9Pt9xyi+bNm6dVq1bpk08+0SOPPKKBAwfqnnvuCXZVO8WoEQAA5gt6eAkNDe20t6XZ66+/riFDhmjp0qWSpMsuu0x79uzRCy+80CvCCwAAMF/Q57zk5uYqNTVVGRkZmjlzpn766ad2y+bk5Gjq1Kk+626++Wbt2bNHdXV1be7j8Xjkdrt9lmDxeTwAs3cBADBFUMPL+PHjtXLlSn300Uf6j//4DxUXF2vSpEkqKytrs3xxcbGSk5N91iUnJ+vMmTMqLS1tc5/s7Gw5HA7vkpaW1u3tAAAAvUdQw0tmZqbuuecejR49Wr/85S+1adMmSdI777zT7j42m83nfXMPx7nrm2VlZcnlcnmXgoKCbqo9AADojYI+56Wl6OhojR49Wrm5uW1uT0lJUXFxsc+6kpIShYaGKiEhoc197Ha77HZ7t9e1LQaPBwAAwHQ9ep8Xj8ej7777Tk6ns83tEydO1JYtW3zWbd68WePGjVNYWFhPVBEAAPRyQQ0vixcv1o4dO5SXl6fPP/9cv/rVr+R2uzVnzhxJjUM+s2fP9pafP3++jhw5okWLFum7777TW2+9peXLl2vx4sXBrCYAALCQoA4bHT16VL/+9a9VWlqqgQMHasKECfrss8+Unp4uSSoqKlJ+fr63fEZGhj744AP99re/1SuvvKLU1FS99NJLveYyaYaKAAAwX1DDy+rVqzvc/vbbb7dad/3112vv3r1BqlH3IccAAGAOnm0EAAAshfDiB4aNAAAwH+EFAABYCuElQPTCAABgDsKLHwym6QIAYDrCCwAAsBTCS4DohQEAwByEFz8wzwUAAPMRXgAAgKUQXgAAgKUQXgLEEBIAAOYgvAAAAEshvAAAAEshvPih5VARo0YAAJiD8AIAACyF8AIAACyF8OIH7qoLAID5CC+B4lppAABMQXgBAACWQnjxA50tAACYj/ACAAAshfASIDphAAAwB+HFDwQWAADMR3gBAACWQngJEJN3AQAwB+HFDwaJBQAA0xFeAACApRBe/EC/CwAA5iO8BIjnHAEAYA7CCwAAsBTCix+YrwsAgPkILwAAwFIILwGiFwYAAHMQXvxCYgEAwGxBDS/Z2dm66qqrFBMTo6SkJN155506ePBgh/ts375dNput1fL9998Hs6oAAMAighpeduzYoQULFuizzz7Tli1bdObMGU2dOlVVVVWd7nvw4EEVFRV5l+HDhwezqn6jDwYAAHOEBvPgH374oc/7FStWKCkpSV9++aWuu+66DvdNSkpSXFxcEGvnP+a5AABgvh6d8+JyuSRJ8fHxnZa94oor5HQ6deONN2rbtm3tlvN4PHK73T4LAADou3osvBiGoUWLFunaa6/VqFGj2i3ndDr15ptvau3atVq3bp0uueQS3Xjjjdq5c2eb5bOzs+VwOLxLWlpasJoAAAB6AZvRQ49KXrBggTZt2qRdu3Zp8ODBfu07ffp02Ww2bdy4sdU2j8cjj8fjfe92u5WWliaXy6XY2NjzrndLuw+f1L2v50iS5l8/TE9lXtqtxwcA4ELldrvlcDi69P3dIz0vjz32mDZu3Kht27b5HVwkacKECcrNzW1zm91uV2xsrM8CAAD6rqBO2DUMQ4899pjWr1+v7du3KyMjI6Dj7Nu3T06ns5trBwAArCio4WXBggX6z//8T73//vuKiYlRcXGxJMnhcCgyMlKSlJWVpWPHjmnlypWSpKVLl2ro0KEaOXKkamtrtWrVKq1du1Zr164NZlW7pOUAG0+VBgDAHEENL6+99pokafLkyT7rV6xYoblz50qSioqKlJ+f791WW1urxYsX69ixY4qMjNTIkSO1adMm3XLLLcGsKgAAsIigDxt15u233/Z5/8QTT+iJJ54IUo0AAIDV8WwjP/TQhVkAAKADhJdAkWMAADAF4QUAAFgK4cUPdLYAAGA+wgsAALAUwkuA6IUBAMAchBc/cLERAADmI7wAAABLIbwEiHu+AABgDsKLH3ieEQAA5iO8AAAASyG8AAAASyG8+KPFqBFTXgAAMAfhBQAAWArhBQAAWArhxQ+MFAEAYD7CS4AIMgAAmIPw4gcm6QIAYD7CCwAAsBTCS4DohQEAwByEFz/weAAAAMxHeAEAAJZCeAEAAJZCePFDy3kuDCEBAGAOwgsAALCUULMrAAAAegfDMHS6rl6u03WNS3Xd2den6+SuOSP36TrVNxj6w52jTKsn4cUPDBQBAKygrr7BGzjKq+vkOl3b4nXjT/fpOpWfrlN5da1PQKmr7/zbLrxfiP7tjpGy2Ww90JrWCC8B4j4vAIBgMgxDlZ4z3sDRMoyUN4URV3WdTyhxNYWRqtr68/rd/UJsckSGyREZptimn41LqPd1gyH1Mye7EF4AAAgmz5n6NoNGuXdoptb7umWPiKtpeOZ8xEQ0ho24qMbAERcZrtim93FNISQuqjGgxEWGy9FULjq8n2m9Kl1BePGDQXcLAFyQDMNQTV2DTlXX6lR1rVzVdTpVXdf4ukWPR1u9JKfrzq8XJDw0xCdoNPZ8hJ8NJFEte0bCFBcVrrjIMMVEhCq0X9+8LofwAgC4oNTVNzQOvTT1eJyqagwdp5rel1fX6lRV49BM8/pT1XWqPdMQ8O+02aTYiLM9HrFNIcMRGdrY4xEZ5u31iPNuaywfEdavG1vfNxBeAACW1NBgqKLmjDd0nKqubRE8mkJI9dkekVNNPys9ZwL+naEhNsVFhWtAVJgGRDUOs8Q1D8NENQ3JnDNM42jqBQkJ6b3DMFZDePEDg0YA0P2aL889N2icqm6cD+IdnmkRQJqHawKdEtLcEzKgKXTENYWRxp6RcA2IDvOGlLimIZoB0eG9fi7IhYLwAgDoVjV19SqvrtPJqsb5IT4/q2p1srpxqKbles95DMlEhfc7Gzyi2ggdUY1hxBF5tsckNjJM/egJsaweCS+vvvqq/vznP6uoqEgjR47U0qVL9Ytf/KLd8jt27NCiRYt04MABpaam6oknntD8+fN7oqpdxuRdABeCuvqmSapVdW2EkLbDSHWAl+mG9bO1GTx8AkmLXpIBUY3zROyhzAm50AQ9vKxZs0YLFy7Uq6++qmuuuUZvvPGGMjMz9e2332rIkCGtyufl5emWW27RvHnztGrVKn3yySd65JFHNHDgQN1zzz3Brm7HyCsALKy+wWiaB1Krk1VNQzMtQ0jTupYhpaImsPkh/UJsGhAVrvjosKaf4RoQHa74qKafLdc3rWNIBl0V9PDy4osv6qGHHtLDDz8sSVq6dKk++ugjvfbaa8rOzm5V/vXXX9eQIUO0dOlSSdJll12mPXv26IUXXjA/vABAL1J7pkEnq2pVVuVRWWVt0+talVV6vK9b9pK4TtcFdINNm03eng5v2GgrhLQIJ7ERoQQRBE1Qw0ttba2+/PJLPfXUUz7rp06dqk8//bTNfXJycjR16lSfdTfffLOWL1+uuro6hYWF+WzzeDzyeDze9263u5tq3zE6YQB0t5Zh5GRVrcoqmwOIp8XrxnBSdh69IrERoW30hIS321PC/BD0NkENL6Wlpaqvr1dycrLP+uTkZBUXF7e5T3FxcZvlz5w5o9LSUjmdTp9t2dnZevbZZ7u34u0wiCwA/NATYaR5eCYhOlwJ/RtDR+Nru+KbQkl8i3ASFxWmsD564zJcOHpkwu65XYeGYXTYndhW+bbWS1JWVpYWLVrkfe92u5WWlnY+1QWANhmGIdfpOpVWenSiolallR7vcrKqVqVNQzeNrz1BCSPnvnZEhnH/EFxwghpeEhMT1a9fv1a9LCUlJa16V5qlpKS0WT40NFQJCQmtytvtdtnt9u6rNIALSn2D4Q0bpZWNPSKllR6dqPSo9JyAUlZZqzN+3likOYwk9j/bA5LYolekcb3d+zo2gjACdCao4SU8PFxjx47Vli1bdNddd3nXb9myRXfccUeb+0ycOFF//etffdZt3rxZ48aNazXfpae1nOjGldJA79U8XHM2hHhUWtk6oDT3mPh7o7PYiFAlxtiV2N+ugf3tSux/tjeEMAIEX9CHjRYtWqRZs2Zp3Lhxmjhxot58803l5+d779uSlZWlY8eOaeXKlZKk+fPna9myZVq0aJHmzZunnJwcLV++XO+9916wqwqgFztT3xhISio8OlHhUUlFjU40hZKzAaXxvet0nV/Httmk+KjGYZrE/vazS0x4i4BiV0L/xjLcVwQwV9DDy4wZM1RWVqZ/+7d/U1FRkUaNGqUPPvhA6enpkqSioiLl5+d7y2dkZOiDDz7Qb3/7W73yyitKTU3VSy+9xGXSQB9VXXtGJe7GHpISt0cnKmpaBBSP9/XJKo9fPST9QmxKaBqiaewlCdfApgBybkCJjwrvs0/fBfoim9HHbhXrdrvlcDjkcrkUGxvbrcfe+u1xPbxyjyRp1oR0/eHOUd16fKCvaGgwdLK61htAmntKmkPKCW9YqVGVH3djDbFJCf3tSoqxa2BMY4/IwBi7T0BpDiVxTGQFLMWf72+ebRQgLpvGhai+wVBZpUfH3R4Vu2t03F2jEneNTw9JSUWNSitrVe9HN0lkWD8lxTaGkaRYu5JiIhrDSdPSHFYSou3cbwQA4QVA4yXA7pozOt4USIpdjYGk2NX4/niFR8ddNTpR6fErlCREh7cIIBE+QcT7MzaC28ID8AvhxQ/0tcCKaurqVdKip8QbUNweb89JsbtGNXVde6pviE1K7G9XiiNCSTERSo61Kzn23GASoYT+4dwMDUBQEF4C1LdmCsGq3DV1KnbVqLD8dONPV42KXacbg4mrRscralRe3fUrbxyRYUqJjVBSUyBJiT0bTpJjI5TiiFBCNJNbAZiL8AL0UhXNwcRVo6Ly0ypy1ajI1fyzcWin0tO1O7jaQ0OU4og4G0KaAknSOQElIoxLgAH0foQXP/SxC7NgokrPGRW7TquwvEUgKa9RkbsxqBS7alTRxWASF9XYW5IaF6kUR4ScTT0k3rASE6HYSJ7wC6DvILwA3ayhwVBppUdHy0/r2KnTOnbOz0LX6S4/88YRGSanI0JOR4RSHJFKbQolqXGRTesiFBXOxxjAhYX/6vnBaOc1Liy1ZxpU7KrR0fLqVuGksLyxN6W2vvPJr7ERoWd7SxyR3pDidETKGdc4nBNt5yMKAOfiv4zAOWrq6nX0VLUKTp3W0VONgaRlSDleUdPphO0Qm+R0RGpQXKRS4yI0aECkBsVFNf1sDCgEEwAIDP/1xAWnocHQ8YoaFZw8rfyT1co/Wa2jTT8LTlXruNvT6THsoSEaFBfZFEYifV8PiFRKbARX5ABAkBBe/MB8Xetw19Qpv6xaR081hZKmoFJwslpHT53udFinvz1UgwdEavCAKA1q1XMSqcT+4UyABQCTEF4CRJAxl2EYKquq1eHSKuWVVulIWbXyyqqUX9bYe9LZvU36hdg0KC5SQ+KjlBYfqbT4qMbXAxp/xkWFEU4AoJcivKDXag4oR8qqlFdarcOlVTpc1rgcKa3u9FLihOhwpcVHNQWTSG8wSYuPktPBsA4AWBXhxS90twSD63SdfjxRqbwTjcGkuSflcGlVhwHFZpNSHZEamhil9IRoZSREa0hClNITojR4QJT6MyEWAPok/useMIKMPxoaDBW6TuvHE1X6saRSP56o1KGSSv14okqllR1PkE11RGhoYnTjkhCloQnRykiMVlp8FHeEBYALEOEF3aqmrl55pVX68USlfiyp8oaUn0orO3zwX0pshDKaAkpGc09KYrSGEFAAAOcgvPiBSbpn1dU36HBplQ4er9DB4sblh+MVOnKyut1/p7B+Ng1NiNawgf01LKnp58D+umhgtGIiwnq2AQAAyyK8oEMNDYaOlZ/W903hpDmk/HiiUnX1baeU2IhQXZzUvymk9NfFTT/TBkQySRYAcN4ILwHqi70wp2vr9V2xWwcK3fq20K1vi9zKPV6h6tr6NstHh/fTiJQYXZIco0uafg5PjuEeKACAoCK8+KEv5ZWTVbX6ttCtA4WuxrBS5NZPJyrV0EYjw/uFaFhSf12S3F8jUmJ0aUqMRiTHaFBcJCEFANDjCC8XAFd1nb46Wq6vCsr11dFyHSh0q8hV02bZxP52jUyN1eWpsRqZGqtLU2I1NCGK4R4AQK9BeAlQbx02qqmr17dF7sagUlCur466lFda1WbZoQlRTSHF0fjTGauk2IgerjEAAP4hvPihNwaW4+4a7T58UrvzTmpfQbm+K3K3OZF2aEKUxqTF6WeD4zR6kEOXOWO4wgcAYEmEFwsxDEM/nqhqDCtNS8HJ063KJUSH6+dpcRrTtPxskEMDosNNqDEAAN2P8NKLGYahI2XV2nWoVJ8cKtXneSd1sqrWp0yITbrMGaurhsZrbPoAXTEkjom0AIA+jfDiB6PF9UZGkK49Kq306NMfy/RJbql2HSrVsXLfnhV7aIh+nhanqzPiNW5ovK4cEsfwDwDggkJ4MZlhGDpQ6Nb/fFei//n+uP73qMtne1g/m64cMkDXXpyoSRcnaNQgh+yh3C4fAHDhIryYoK6+QZ8cKtXW747rf74raXXZ8mXOWF17cYKuuThRV2fEKyqc0wQAQDO+Ff1wPlcb1TcY+jyvTH/9qkh/+6ZI5dV13m2RYf107fBE/fKyJE25NElJMVyuDABAewgvAepqkDlUUqnVX+Rr41eFKqnweNcn9rfr5pHJ+uVlyZo4LIEnJwMA0EWElyDwnKnXh98U693P8/VF3knvekdkmDJHpWj6mFRNuChB/UK4IggAAH8RXvzQWWdL7ZkG/deeAr2y7ZB3HkuITbrh0iTNuGqIrh8xUOGh3GYfAIDzQXgJUMsgc6a+Qev2HtNLH+fq6KnGS5uTY+26/+p03XfVYDkdkeZUEgCAPojwEqBduaU6WVWrHT+U6P9tzdXhsmpJjXNZFkwZpl9fPYR5LAAABEHQxjAOHz6shx56SBkZGYqMjNSwYcP0zDPPqLa2tsP95s6dK5vN5rNMmDAhWNX0i9Film6xu0ZX/mGLfrvmKx0uq1Z8dLj+9ZbL9Pcnpuj/XJNBcAEAIEiC1vPy/fffq6GhQW+88YYuvvhiffPNN5o3b56qqqr0wgsvdLjvtGnTtGLFCu/78PDe/Vye/3vzJZo7aaii7XRkAQAQbEH7tp02bZqmTZvmfX/RRRfp4MGDeu211zoNL3a7XSkpKcGqWrd6/TdXatoop9nVAADggtGjl764XC7Fx8d3Wm779u1KSkrSiBEjNG/ePJWUlLRb1uPxyO12+yw9ZemMnxNcAADoYT0WXn788Ue9/PLLmj9/foflMjMz9e677+rjjz/WX/7yF+3evVs33HCDPB5Pm+Wzs7PlcDi8S1paWjCq36b0hKge+10AAKCR3+FlyZIlrSbUnrvs2bPHZ5/CwkJNmzZN9957rx5++OEOjz9jxgzdeuutGjVqlKZPn66//e1v+uGHH7Rp06Y2y2dlZcnlcnmXgoICf5sUsIsS+/fY7wIAAI38nvPy6KOPaubMmR2WGTp0qPd1YWGhpkyZookTJ+rNN9/0u4JOp1Pp6enKzc1tc7vdbpfdbvf7uIGorq2XJMVGhOq134yVIyqsR34vAAA4y+/wkpiYqMTExC6VPXbsmKZMmaKxY8dqxYoVCgnxf5SqrKxMBQUFcjrNnVviqq7TH/77W0lS5iinrrm4a/8GAACgewVtzkthYaEmT56stLQ0vfDCCzpx4oSKi4tVXFzsU+7SSy/V+vXrJUmVlZVavHixcnJydPjwYW3fvl3Tp09XYmKi7rrrrmBVtUtsIWd7XoxOHxQAAACCJWiXSm/evFmHDh3SoUOHNHjwYJ9tLW/2dvDgQblcLklSv3799PXXX2vlypUqLy+X0+nUlClTtGbNGsXExASrql0SGxGm6PB+qqqt16Rh9LoAAGAWm9EySfQBbrdbDodDLpdLsbGx3XrsQyUV+vqYS3f+fJBsNp4IDQBAd/Hn+5tbwvrh4qQYXZxkbg8QAAAXuh69SR0AAMD5IrwAAABLIbwAAABLIbwAAABLIbwAAABLIbwAAABLIbwAAABLIbwAAABLIbwAAABLIbwAAABLIbwAAABLIbwAAABLIbwAAABL6XNPlTYMQ1Ljo7UBAIA1NH9vN3+Pd6TPhZeKigpJUlpamsk1AQAA/qqoqJDD4eiwjM3oSsSxkIaGBhUWFiomJkY2m61bj+12u5WWlqaCggLFxsZ267F7A9pnbbTP2miftdG+82cYhioqKpSamqqQkI5ntfS5npeQkBANHjw4qL8jNja2T/5xNqN91kb7rI32WRvtOz+d9bg0Y8IuAACwFMILAACwFMKLH+x2u5555hnZ7XazqxIUtM/aaJ+10T5ro309q89N2AUAAH0bPS8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC9d9OqrryojI0MREREaO3as/v73v5tdpS7Jzs7WVVddpZiYGCUlJenOO+/UwYMHfcrMnTtXNpvNZ5kwYYJPGY/Ho8cee0yJiYmKjo7W7bffrqNHj/ZkU9q0ZMmSVnVPSUnxbjcMQ0uWLFFqaqoiIyM1efJkHThwwOcYvbVtkjR06NBW7bPZbFqwYIEk6527nTt3avr06UpNTZXNZtOGDRt8tnfX+Tp16pRmzZolh8Mhh8OhWbNmqby8PMit67h9dXV1evLJJzV69GhFR0crNTVVs2fPVmFhoc8xJk+e3Oqczpw50/T2dXbuuutvsTeeO0ltfg5tNpv+/Oc/e8v01nMnde27wEqfP8JLF6xZs0YLFy7Uv/7rv2rfvn36xS9+oczMTOXn55tdtU7t2LFDCxYs0GeffaYtW7bozJkzmjp1qqqqqnzKTZs2TUVFRd7lgw8+8Nm+cOFCrV+/XqtXr9auXbtUWVmp2267TfX19T3ZnDaNHDnSp+5ff/21d9uf/vQnvfjii1q2bJl2796tlJQU3XTTTd5nYEm9u227d+/2aduWLVskSffee6+3jJXOXVVVlcaMGaNly5a1ub27ztf999+v/fv368MPP9SHH36o/fv3a9asWaa2r7q6Wnv37tXTTz+tvXv3at26dfrhhx90++23tyo7b948n3P6xhtv+Gw3o32dnTupe/4We+O5k+TTrqKiIr311luy2Wy65557fMr1xnMnde27wFKfPwOduvrqq4358+f7rLv00kuNp556yqQaBa6kpMSQZOzYscO7bs6cOcYdd9zR7j7l5eVGWFiYsXr1au+6Y8eOGSEhIcaHH34YzOp26plnnjHGjBnT5raGhgYjJSXFeO6557zrampqDIfDYbz++uuGYfTutrXl8ccfN4YNG2Y0NDQYhmHtcyfJWL9+vfd9d52vb7/91pBkfPbZZ94yOTk5hiTj+++/D3Krzjq3fW354osvDEnGkSNHvOuuv/564/HHH293n97Qvrba1h1/i72hbYbRtXN3xx13GDfccIPPOiucu2bnfhdY7fNHz0snamtr9eWXX2rq1Kk+66dOnapPP/3UpFoFzuVySZLi4+N91m/fvl1JSUkaMWKE5s2bp5KSEu+2L7/8UnV1dT7/BqmpqRo1alSv+DfIzc1VamqqMjIyNHPmTP3000+SpLy8PBUXF/vU22636/rrr/fWu7e3raXa2lqtWrVKDz74oM9DR6187lrqrvOVk5Mjh8Oh8ePHe8tMmDBBDoej17XZ5XLJZrMpLi7OZ/27776rxMREjRw5UosXL/b5P9/e3L7z/VvszW1r6fjx49q0aZMeeuihVtuscu7O/S6w2uevzz2YsbuVlpaqvr5eycnJPuuTk5NVXFxsUq0CYxiGFi1apGuvvVajRo3yrs/MzNS9996r9PR05eXl6emnn9YNN9ygL7/8Una7XcXFxQoPD9eAAQN8jtcb/g3Gjx+vlStXasSIETp+/Lj+/d//XZMmTdKBAwe8dWvr3B05ckSSenXbzrVhwwaVl5dr7ty53nVWPnfn6q7zVVxcrKSkpFbHT0pK6lVtrqmp0VNPPaX777/f50F3DzzwgDIyMpSSkqJvvvlGWVlZ+uqrr7xDhr21fd3xt9hb23aud955RzExMbr77rt91lvl3LX1XWC1zx/hpYta/p+u1Hjyz13X2z366KP63//9X+3atctn/YwZM7yvR40apXHjxik9PV2bNm1q9eFsqTf8G2RmZnpfjx49WhMnTtSwYcP0zjvveCcLBnLuekPbzrV8+XJlZmYqNTXVu87K56493XG+2irfm9pcV1enmTNnqqGhQa+++qrPtnnz5nlfjxo1SsOHD9e4ceO0d+9eXXnllZJ6Z/u662+xN7btXG+99ZYeeOABRURE+Ky3yrlr77tAss7nj2GjTiQmJqpfv36tEmNJSUmrhNqbPfbYY9q4caO2bdumwYMHd1jW6XQqPT1dubm5kqSUlBTV1tbq1KlTPuV6479BdHS0Ro8erdzcXO9VRx2dO6u07ciRI9q6dasefvjhDstZ+dx11/lKSUnR8ePHWx3/xIkTvaLNdXV1uu+++5SXl6ctW7b49Lq05corr1RYWJjPOe3N7WsWyN+iFdr297//XQcPHuz0syj1znPX3neB1T5/hJdOhIeHa+zYsd5uv2ZbtmzRpEmTTKpV1xmGoUcffVTr1q3Txx9/rIyMjE73KSsrU0FBgZxOpyRp7NixCgsL8/k3KCoq0jfffNPr/g08Ho++++47OZ1Ob/dty3rX1tZqx44d3npbpW0rVqxQUlKSbr311g7LWfncddf5mjhxolwul7744gtvmc8//1wul8v0NjcHl9zcXG3dulUJCQmd7nPgwAHV1dV5z2lvbl9LgfwtWqFty5cv19ixYzVmzJhOy/amc9fZd4HlPn/dNvW3D1u9erURFhZmLF++3Pj222+NhQsXGtHR0cbhw4fNrlqn/umf/slwOBzG9u3bjaKiIu9SXV1tGIZhVFRUGL/73e+MTz/91MjLyzO2bdtmTJw40Rg0aJDhdru9x5k/f74xePBgY+vWrcbevXuNG264wRgzZoxx5swZs5pmGIZh/O53vzO2b99u/PTTT8Znn31m3HbbbUZMTIz33Dz33HOGw+Ew1q1bZ3z99dfGr3/9a8PpdFqibc3q6+uNIUOGGE8++aTPeiueu4qKCmPfvn3Gvn37DEnGiy++aOzbt897tU13na9p06YZP/vZz4ycnBwjJyfHGD16tHHbbbeZ2r66ujrj9ttvNwYPHmzs37/f5/Po8XgMwzCMQ4cOGc8++6yxe/duIy8vz9i0aZNx6aWXGldccYXp7euobd35t9gbz10zl8tlREVFGa+99lqr/XvzuTOMzr8LDMNanz/CSxe98sorRnp6uhEeHm5ceeWVPpca92aS2lxWrFhhGIZhVFdXG1OnTjUGDhxohIWFGUOGDDHmzJlj5Ofn+xzn9OnTxqOPPmrEx8cbkZGRxm233daqjBlmzJhhOJ1OIywszEhNTTXuvvtu48CBA97tDQ0NxjPPPGOkpKQYdrvduO6664yvv/7a5xi9tW3NPvroI0OScfDgQZ/1Vjx327Zta/Pvcc6cOYZhdN/5KisrMx544AEjJibGiImJMR544AHj1KlTprYvLy+v3c/jtm3bDMMwjPz8fOO6664z4uPjjfDwcGPYsGHGP//zPxtlZWWmt6+jtnXn32JvPHfN3njjDSMyMtIoLy9vtX9vPneG0fl3gWFY6/Nna2oUAACAJTDnBQAAWArhBQAAWArhBQAAWArhBQAAWArhBQAAWArhBQAAWArhBQAAWArhBQAAWArhBQAAWArhBQAAWArhBQAAWArhBQAAWMr/DwDGFbdoBshMAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(exp.dataloader.train_dataset.scaled_data[:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38]",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
