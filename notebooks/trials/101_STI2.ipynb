{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from enum import Enum\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import signal\n",
    "import threading\n",
    "import time\n",
    "import hashlib\n",
    "from prettytable import PrettyTable\n",
    "import sys\n",
    "####\n",
    "from typing import Dict, List, Type, Union\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchmetrics import MeanSquaredError, MetricCollection, MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from torch_timeseries.data.scaler import *\n",
    "from torch_timeseries.datasets import *\n",
    "from torch_timeseries.experiments.experiment import Experiment\n",
    "\n",
    "from torch_timeseries.datasets.dataset import TimeSeriesDataset\n",
    "from torch_timeseries.datasets.splitter import SequenceRandomSplitter, SequenceSplitter\n",
    "from torch_timeseries.datasets.dataloader import (\n",
    "    ChunkSequenceTimefeatureDataLoader,\n",
    "    DDPChunkSequenceTimefeatureDataLoader,\n",
    ")\n",
    "from torch_timeseries.datasets.wrapper import MultiStepTimeFeatureSet\n",
    "from torch_timeseries.models.Informer import Informer\n",
    "from torch.nn import MSELoss, L1Loss\n",
    "\n",
    "from torch.optim import Optimizer, Adam\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, Subset\n",
    "\n",
    "from torch.nn import DataParallel\n",
    "import torch.nn as nn\n",
    "from dataclasses import asdict,dataclass\n",
    "\n",
    "from torch_timeseries.nn.metric import R2, Corr, TrendAcc,RMSE, compute_corr, compute_r2\n",
    "from torch_timeseries.metrics.masked_mape import MaskedMAPE\n",
    "from torch_timeseries.utils.early_stopping import EarlyStopping\n",
    "import json\n",
    "import codecs\n",
    "\n",
    "\n",
    "from torch_timeseries.layers.tcn_output8 import TCNOuputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# device = 'device'\n",
    "\n",
    "# dataset : TimeSeriesDataset = ExchangeRate(root='/notebooks/pytorch_timeseries/')\n",
    "# scaler = StandarScaler(device='')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from torch_timeseries.datasets.dataset import TimeSeriesStaticGraphDataset\n",
    "\n",
    "\n",
    "class STI(torch.nn.Module):\n",
    "    # \n",
    "    def __init__(self,seq_len, latent_dim,num_nodes,out_seq_len,tcn_layers=5,dilated_factor=2,tcn_channel=16,kernel_set=[2,3,6,7],d0=1, layer_norm_affline=True) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.tcn = TCNOuputLayer(\n",
    "                        seq_len,num_nodes,out_seq_len,\n",
    "                        tcn_layers,3,dilated_factor,\n",
    "                        tcn_channel,kernel_set=kernel_set,d0=d0,\n",
    "                        layer_norm_affline=True     \n",
    "                    )\n",
    "\n",
    "\n",
    "        self.spatial_projection = nn.Sequential(\n",
    "            nn.Linear(seq_len, latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(latent_dim, latent_dim)\n",
    "        )\n",
    "        self.temporal_projection =nn.GRU(\n",
    "            num_nodes,latent_dim, batch_first=True\n",
    "        )\n",
    "        \n",
    "        # self.freq_projection = nn.Sequential(\n",
    "        #     nn.Linear(num_nodes, self.tcn_input_dim),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(self.tcn_input_dim, self.tcn_input_dim)\n",
    "        # )\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        self.feature_rebuild = nn.Sequential(\n",
    "            nn.Linear(latent_dim, seq_len),\n",
    "            torch.nn.ELU(),\n",
    "            nn.Linear(seq_len, seq_len),\n",
    "        )\n",
    "\n",
    "        \n",
    "        self.time_rebuild = nn.GRU(latent_dim, num_nodes, batch_first=True)\n",
    "        \n",
    "        # self.freq_rebuild = nn.Sequential(\n",
    "        #     nn.Linear(seq_len, latent_dim),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(latent_dim, num_nodes)\n",
    "        # )\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x : (B, N, T)\n",
    "        \n",
    "        seq_last = x[:,:,-1:].detach()\n",
    "        x = x - seq_last\n",
    "        # import pdb;pdb.set_trace\n",
    "        \n",
    "        \n",
    "        Xs = self.spatial_projection(x) # (B, N, latent_dim)\n",
    "        Xt, _ = self.temporal_projection(x.transpose(1, 2)) # (B, T, latent_dim)\n",
    "        # Xf = torch.abs(torch.fft.fft(x, dim=2, norm='forward'))# (B, N, T)\n",
    "        \n",
    "        # Xf = self.freq_projection(Xf.transpose(1,2 ))  # ï¼ˆB, T, latent_dim)\n",
    "        \n",
    "        Zs = self.feature_rebuild(Xs)  # (B, N, T)\n",
    "        Zt, _ = self.time_rebuild(Xt)\n",
    "        Zt = Zt.transpose(1,2) # (B, N, T)\n",
    "        # Zf = self.freq_rebuild(Xf.transpose(1, 2)).transpose(1, 2) # (B, N, tcn_input_dim)\n",
    "        \n",
    "        Z = torch.stack([Zs, Zt, x], dim=1)\n",
    "        O = self.tcn(Z) # (B, O , N)\n",
    "        \n",
    "        \n",
    "        O = (O.transpose(1,2) + seq_last).transpose(1,2)\n",
    "        return O\n",
    "        # Zs = self.freq_projection(Xs)\n",
    "        # Zt = self.freq_projection(Xt)\n",
    "        # Zf = self.freq_projection(Xf)\n",
    "    # self.feq_projection = nn.Sequential(\n",
    "    #     nn.Linear()\n",
    "    # )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "@dataclass\n",
    "class TSExperiment(Experiment):\n",
    "    \n",
    "    latent_dim: int = 1024\n",
    "    tcn_layers : int = 5\n",
    "\n",
    "    def _process_one_batch(self, batch_x, batch_y, batch_x_date_enc, batch_y_date_enc):\n",
    "        # inputs:\n",
    "        # batch_x: (B, T, N)\n",
    "        # batch_y: (B, O, N)\n",
    "        # ouputs:\n",
    "        # - pred: (B, N)/(B, O, N)\n",
    "        # - label: (B, N)/(B, O, N)\n",
    "        batch_size = batch_x.size(0)\n",
    "        batch_x = batch_x.to(self.device, dtype=torch.float32)\n",
    "        batch_y = batch_y.to(self.device, dtype=torch.float32)\n",
    "        batch_x_date_enc = batch_x_date_enc.to(self.device).float()\n",
    "        batch_y_date_enc = batch_y_date_enc.to(self.device).float()\n",
    "        batch_x = batch_x.transpose(1,2)\n",
    "        outputs = self.model(batch_x)  # torch.Size([batch_size, num_nodes])\n",
    "        # single step prediction\n",
    "        return outputs, batch_y\n",
    "\n",
    "\n",
    "    def _init_model(self):\n",
    "        predefined_NN_adj = None\n",
    "        padded_A = None\n",
    "        if isinstance(self.dataset, TimeSeriesStaticGraphDataset) and self.pred_len > 1:\n",
    "            predefined_NN_adj = torch.tensor(self.dataset.adj).to(self.device)\n",
    "            D = torch.diag(torch.sum(predefined_NN_adj, dim=1))\n",
    "            D_sqrt_inv = torch.sqrt(torch.inverse(D))\n",
    "            normalized_predefined_adj = D_sqrt_inv @predefined_NN_adj @ D_sqrt_inv\n",
    "            padded_A = torch.nn.functional.pad(normalized_predefined_adj, (0, self.windows, 0, self.windows), mode='constant', value=0).float()\n",
    "\n",
    "        else:\n",
    "            padded_A = None\n",
    "\n",
    "        if isinstance(self.dataset, PeMS_D7):\n",
    "            temporal_embed_dim = 0\n",
    "        else:\n",
    "            temporal_embed_dim = 4\n",
    "        self.model = STI(\n",
    "            tcn_layers=self.tcn_layers,\n",
    "            seq_len=self.windows, latent_dim=self.latent_dim,num_nodes=self.dataset.num_features,out_seq_len=self.pred_len,dilated_factor=2,tcn_channel=16,kernel_set=[2,3,6,7],d0=1, layer_norm_affline=True\n",
    "        )\n",
    "        self.model = self.model.to(self.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /notebooks/pytorch_timeseries/data/solar_AL/solar_AL.txt.gz\n",
      "Extracting /notebooks/pytorch_timeseries/data/solar_AL/solar_AL.txt.gz to /notebooks/pytorch_timeseries/data/solar_AL\n",
      "train steps: 36601\n",
      "val steps: 10321\n",
      "test steps: 5065\n",
      "torch.get_default_dtype() torch.float32\n",
      "Creating running results saving dir: './results/runs/SolarEnergy/w168h24s1/976f6cd3fa50e7bd52808990043c4f4d'.\n",
      "run : 0 in seed: 662\n",
      "+---------------------------------------+------------+\n",
      "|                Modules                | Parameters |\n",
      "+---------------------------------------+------------+\n",
      "|        tcn.channel_layer.weight       |     48     |\n",
      "|         tcn.channel_layer.bias        |     16     |\n",
      "| tcn.tcn.filter_convs.0.tconv.0.weight |    128     |\n",
      "|  tcn.tcn.filter_convs.0.tconv.0.bias  |     4      |\n",
      "| tcn.tcn.filter_convs.0.tconv.1.weight |    192     |\n",
      "|  tcn.tcn.filter_convs.0.tconv.1.bias  |     4      |\n",
      "| tcn.tcn.filter_convs.0.tconv.2.weight |    384     |\n",
      "|  tcn.tcn.filter_convs.0.tconv.2.bias  |     4      |\n",
      "| tcn.tcn.filter_convs.0.tconv.3.weight |    448     |\n",
      "|  tcn.tcn.filter_convs.0.tconv.3.bias  |     4      |\n",
      "| tcn.tcn.filter_convs.1.tconv.0.weight |    128     |\n",
      "|  tcn.tcn.filter_convs.1.tconv.0.bias  |     4      |\n",
      "| tcn.tcn.filter_convs.1.tconv.1.weight |    192     |\n",
      "|  tcn.tcn.filter_convs.1.tconv.1.bias  |     4      |\n",
      "| tcn.tcn.filter_convs.1.tconv.2.weight |    384     |\n",
      "|  tcn.tcn.filter_convs.1.tconv.2.bias  |     4      |\n",
      "| tcn.tcn.filter_convs.1.tconv.3.weight |    448     |\n",
      "|  tcn.tcn.filter_convs.1.tconv.3.bias  |     4      |\n",
      "| tcn.tcn.filter_convs.2.tconv.0.weight |    128     |\n",
      "|  tcn.tcn.filter_convs.2.tconv.0.bias  |     4      |\n",
      "| tcn.tcn.filter_convs.2.tconv.1.weight |    192     |\n",
      "|  tcn.tcn.filter_convs.2.tconv.1.bias  |     4      |\n",
      "| tcn.tcn.filter_convs.2.tconv.2.weight |    384     |\n",
      "|  tcn.tcn.filter_convs.2.tconv.2.bias  |     4      |\n",
      "| tcn.tcn.filter_convs.2.tconv.3.weight |    448     |\n",
      "|  tcn.tcn.filter_convs.2.tconv.3.bias  |     4      |\n",
      "| tcn.tcn.filter_convs.3.tconv.0.weight |    128     |\n",
      "|  tcn.tcn.filter_convs.3.tconv.0.bias  |     4      |\n",
      "| tcn.tcn.filter_convs.3.tconv.1.weight |    192     |\n",
      "|  tcn.tcn.filter_convs.3.tconv.1.bias  |     4      |\n",
      "| tcn.tcn.filter_convs.3.tconv.2.weight |    384     |\n",
      "|  tcn.tcn.filter_convs.3.tconv.2.bias  |     4      |\n",
      "| tcn.tcn.filter_convs.3.tconv.3.weight |    448     |\n",
      "|  tcn.tcn.filter_convs.3.tconv.3.bias  |     4      |\n",
      "| tcn.tcn.filter_convs.4.tconv.0.weight |    128     |\n",
      "|  tcn.tcn.filter_convs.4.tconv.0.bias  |     4      |\n",
      "| tcn.tcn.filter_convs.4.tconv.1.weight |    192     |\n",
      "|  tcn.tcn.filter_convs.4.tconv.1.bias  |     4      |\n",
      "| tcn.tcn.filter_convs.4.tconv.2.weight |    384     |\n",
      "|  tcn.tcn.filter_convs.4.tconv.2.bias  |     4      |\n",
      "| tcn.tcn.filter_convs.4.tconv.3.weight |    448     |\n",
      "|  tcn.tcn.filter_convs.4.tconv.3.bias  |     4      |\n",
      "|  tcn.tcn.gate_convs.0.tconv.0.weight  |    128     |\n",
      "|   tcn.tcn.gate_convs.0.tconv.0.bias   |     4      |\n",
      "|  tcn.tcn.gate_convs.0.tconv.1.weight  |    192     |\n",
      "|   tcn.tcn.gate_convs.0.tconv.1.bias   |     4      |\n",
      "|  tcn.tcn.gate_convs.0.tconv.2.weight  |    384     |\n",
      "|   tcn.tcn.gate_convs.0.tconv.2.bias   |     4      |\n",
      "|  tcn.tcn.gate_convs.0.tconv.3.weight  |    448     |\n",
      "|   tcn.tcn.gate_convs.0.tconv.3.bias   |     4      |\n",
      "|  tcn.tcn.gate_convs.1.tconv.0.weight  |    128     |\n",
      "|   tcn.tcn.gate_convs.1.tconv.0.bias   |     4      |\n",
      "|  tcn.tcn.gate_convs.1.tconv.1.weight  |    192     |\n",
      "|   tcn.tcn.gate_convs.1.tconv.1.bias   |     4      |\n",
      "|  tcn.tcn.gate_convs.1.tconv.2.weight  |    384     |\n",
      "|   tcn.tcn.gate_convs.1.tconv.2.bias   |     4      |\n",
      "|  tcn.tcn.gate_convs.1.tconv.3.weight  |    448     |\n",
      "|   tcn.tcn.gate_convs.1.tconv.3.bias   |     4      |\n",
      "|  tcn.tcn.gate_convs.2.tconv.0.weight  |    128     |\n",
      "|   tcn.tcn.gate_convs.2.tconv.0.bias   |     4      |\n",
      "|  tcn.tcn.gate_convs.2.tconv.1.weight  |    192     |\n",
      "|   tcn.tcn.gate_convs.2.tconv.1.bias   |     4      |\n",
      "|  tcn.tcn.gate_convs.2.tconv.2.weight  |    384     |\n",
      "|   tcn.tcn.gate_convs.2.tconv.2.bias   |     4      |\n",
      "|  tcn.tcn.gate_convs.2.tconv.3.weight  |    448     |\n",
      "|   tcn.tcn.gate_convs.2.tconv.3.bias   |     4      |\n",
      "|  tcn.tcn.gate_convs.3.tconv.0.weight  |    128     |\n",
      "|   tcn.tcn.gate_convs.3.tconv.0.bias   |     4      |\n",
      "|  tcn.tcn.gate_convs.3.tconv.1.weight  |    192     |\n",
      "|   tcn.tcn.gate_convs.3.tconv.1.bias   |     4      |\n",
      "|  tcn.tcn.gate_convs.3.tconv.2.weight  |    384     |\n",
      "|   tcn.tcn.gate_convs.3.tconv.2.bias   |     4      |\n",
      "|  tcn.tcn.gate_convs.3.tconv.3.weight  |    448     |\n",
      "|   tcn.tcn.gate_convs.3.tconv.3.bias   |     4      |\n",
      "|  tcn.tcn.gate_convs.4.tconv.0.weight  |    128     |\n",
      "|   tcn.tcn.gate_convs.4.tconv.0.bias   |     4      |\n",
      "|  tcn.tcn.gate_convs.4.tconv.1.weight  |    192     |\n",
      "|   tcn.tcn.gate_convs.4.tconv.1.bias   |     4      |\n",
      "|  tcn.tcn.gate_convs.4.tconv.2.weight  |    384     |\n",
      "|   tcn.tcn.gate_convs.4.tconv.2.bias   |     4      |\n",
      "|  tcn.tcn.gate_convs.4.tconv.3.weight  |    448     |\n",
      "|   tcn.tcn.gate_convs.4.tconv.3.bias   |     4      |\n",
      "|    tcn.tcn.residual_convs.0.weight    |    256     |\n",
      "|     tcn.tcn.residual_convs.0.bias     |     16     |\n",
      "|    tcn.tcn.residual_convs.1.weight    |    256     |\n",
      "|     tcn.tcn.residual_convs.1.bias     |     16     |\n",
      "|    tcn.tcn.residual_convs.2.weight    |    256     |\n",
      "|     tcn.tcn.residual_convs.2.bias     |     16     |\n",
      "|    tcn.tcn.residual_convs.3.weight    |    256     |\n",
      "|     tcn.tcn.residual_convs.3.bias     |     16     |\n",
      "|    tcn.tcn.residual_convs.4.weight    |    256     |\n",
      "|     tcn.tcn.residual_convs.4.bias     |     16     |\n",
      "|      tcn.tcn.skip_convs.0.weight      |   46336    |\n",
      "|       tcn.tcn.skip_convs.0.bias       |     16     |\n",
      "|      tcn.tcn.skip_convs.1.weight      |   43264    |\n",
      "|       tcn.tcn.skip_convs.1.bias       |     16     |\n",
      "|      tcn.tcn.skip_convs.2.weight      |   37120    |\n",
      "|       tcn.tcn.skip_convs.2.bias       |     16     |\n",
      "|      tcn.tcn.skip_convs.3.weight      |   24832    |\n",
      "|       tcn.tcn.skip_convs.3.bias       |     16     |\n",
      "|      tcn.tcn.skip_convs.4.weight      |    256     |\n",
      "|       tcn.tcn.skip_convs.4.bias       |     16     |\n",
      "|         tcn.tcn.norms.0.weight        |   396752   |\n",
      "|          tcn.tcn.norms.0.bias         |   396752   |\n",
      "|         tcn.tcn.norms.1.weight        |   370448   |\n",
      "|          tcn.tcn.norms.1.bias         |   370448   |\n",
      "|         tcn.tcn.norms.2.weight        |   317840   |\n",
      "|          tcn.tcn.norms.2.bias         |   317840   |\n",
      "|         tcn.tcn.norms.3.weight        |   212624   |\n",
      "|          tcn.tcn.norms.3.bias         |   212624   |\n",
      "|         tcn.tcn.norms.4.weight        |    2192    |\n",
      "|          tcn.tcn.norms.4.bias         |    2192    |\n",
      "|          tcn.tcn.skip0.weight         |   47872    |\n",
      "|           tcn.tcn.skip0.bias          |     16     |\n",
      "|          tcn.tcn.skipE.weight         |    256     |\n",
      "|           tcn.tcn.skipE.bias          |     16     |\n",
      "|        tcn.tcn.end_conv.weight        |    256     |\n",
      "|         tcn.tcn.end_conv.bias         |     16     |\n",
      "|          tcn.end_layer.weight         |     16     |\n",
      "|           tcn.end_layer.bias          |     1      |\n",
      "|      spatial_projection.0.weight      |    2688    |\n",
      "|       spatial_projection.0.bias       |     16     |\n",
      "|      spatial_projection.2.weight      |    256     |\n",
      "|       spatial_projection.2.bias       |     16     |\n",
      "|    temporal_projection.weight_ih_l0   |    6576    |\n",
      "|    temporal_projection.weight_hh_l0   |    768     |\n",
      "|     temporal_projection.bias_ih_l0    |     48     |\n",
      "|     temporal_projection.bias_hh_l0    |     48     |\n",
      "|        feature_rebuild.0.weight       |    2688    |\n",
      "|         feature_rebuild.0.bias        |    168     |\n",
      "|        feature_rebuild.2.weight       |   28224    |\n",
      "|         feature_rebuild.2.bias        |    168     |\n",
      "|       time_rebuild.weight_ih_l0       |    6576    |\n",
      "|       time_rebuild.weight_hh_l0       |   56307    |\n",
      "|        time_rebuild.bias_ih_l0        |    411     |\n",
      "|        time_rebuild.bias_hh_l0        |    411     |\n",
      "+---------------------------------------+------------+\n",
      "Total Trainable Params: 2918522\n",
      "model parameters: 2918522\n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36601/36601 [07:47<00:00, 78.24it/s, epoch=0, loss=0.107, lr=0.0003] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost time: 467.78897404670715\n",
      "Val on train....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36601/36601 [01:47<00:00, 339.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val on train result: {'corr': 0.4159376621246338, 'mae': 0.213774174451828, 'mse': 0.1458180546760559, 'r2': 0.8619430065155029, 'r2_weighted': 0.8618839979171753}\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10321/10321 [00:34<00:00, 300.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.42117589712142944, 'mae': 0.2072087526321411, 'mse': 0.14305457472801208, 'r2': 0.8477813005447388, 'r2_weighted': 0.848039984703064}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5065/5065 [00:15<00:00, 320.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.36204397678375244, 'mae': 0.2029394507408142, 'mse': 0.13793721795082092, 'r2': 0.7902147173881531, 'r2_weighted': 0.7915778160095215}\n",
      "Validation loss decreased (inf --> 0.143055).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/SolarEnergy/w168h24s1/976f6cd3fa50e7bd52808990043c4f4d'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36601/36601 [07:43<00:00, 78.90it/s, epoch=1, loss=0.102, lr=0.0003] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 cost time: 1089.7800695896149\n",
      "Val on train....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36601/36601 [01:55<00:00, 315.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val on train result: {'corr': 0.44723179936408997, 'mae': 0.20872606337070465, 'mse': 0.13900160789489746, 'r2': 0.8683778047561646, 'r2_weighted': 0.8683403730392456}\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10321/10321 [00:34<00:00, 300.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.4656623899936676, 'mae': 0.2078491598367691, 'mse': 0.1411900371313095, 'r2': 0.8498681783676147, 'r2_weighted': 0.8500206470489502}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5065/5065 [00:17<00:00, 289.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.4017241895198822, 'mae': 0.20357444882392883, 'mse': 0.13642486929893494, 'r2': 0.7929663062095642, 'r2_weighted': 0.7938629388809204}\n",
      "Validation loss decreased (0.143055 --> 0.141190).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/SolarEnergy/w168h24s1/976f6cd3fa50e7bd52808990043c4f4d'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36601/36601 [07:51<00:00, 77.56it/s, epoch=2, loss=0.0919, lr=0.0003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 cost time: 1729.615253686905\n",
      "Val on train....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36601/36601 [01:58<00:00, 309.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val on train result: {'corr': 0.44611379504203796, 'mae': 0.21083886921405792, 'mse': 0.13652488589286804, 'r2': 0.8707109689712524, 'r2_weighted': 0.870686411857605}\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10321/10321 [00:33<00:00, 304.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.4752410054206848, 'mae': 0.21571846306324005, 'mse': 0.14498572051525116, 'r2': 0.8457903265953064, 'r2_weighted': 0.8459887504577637}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5065/5065 [00:17<00:00, 290.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.4263874888420105, 'mae': 0.21755164861679077, 'mse': 0.14380308985710144, 'r2': 0.7813393473625183, 'r2_weighted': 0.7827145457267761}\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Saving run checkpoint to './results/runs/SolarEnergy/w168h24s1/976f6cd3fa50e7bd52808990043c4f4d'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–‰       | 10816/36601 [02:20<05:36, 76.72it/s, epoch=3, loss=0.159, lr=0.000299] "
     ]
    }
   ],
   "source": [
    "exp = TSExperiment(\n",
    "    latent_dim=16,\n",
    "    dataset_type=\"SolarEnergy\",\n",
    "    tcn_layers=5,\n",
    "    epochs=100,\n",
    "    horizon=24,\n",
    "    windows=168,\n",
    "    data_path='/notebooks/pytorch_timeseries/data/',\n",
    ")\n",
    "# model = STI(168, 128, 9, 1)\n",
    "# out = model(data)\n",
    "\n",
    "exp.run(seed=662)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xf = torch.fft.fft(data, dim=2, norm='forward')[:, :, :]\n",
    "amp = torch.abs(Xf)\n",
    "amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3273,  0.1516,  0.0161, -0.8483,  0.0766,  0.7280,  0.6113, -0.0470,\n",
      "         0.9393,  0.6909,  0.0947,  0.8419,  0.1639, -0.1819,  1.0376,  0.0166,\n",
      "        -0.7076,  0.9921,  0.2978, -0.4104, -1.0616,  0.6393,  0.1030,  0.5463,\n",
      "        -0.3269,  0.1066, -0.1008,  0.2158, -0.1032, -0.3987, -0.4024, -0.3123],\n",
      "       grad_fn=<SelectBackward0>) tensor([-0.4796, -0.6486, -1.6920, -1.0470, -0.4733, -0.2575, -0.1732, -0.4943,\n",
      "         0.1441, -0.6750,  0.2937, -0.0437, -0.0987,  0.2391,  0.2676, -0.3876,\n",
      "         0.9132,  0.7786, -0.3593, -0.1810, -1.0035, -1.1220, -0.5471,  0.9383,\n",
      "        -0.9157,  0.2677, -0.0436,  0.3239,  0.2225,  0.7437,  0.0334,  0.9020],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "torch.Size([7, 32]) torch.Size([7, 32])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4796, -0.6486, -1.6920, -1.0470, -0.4733, -0.2575, -0.1732, -0.4943,\n",
       "         0.1441, -0.6750,  0.2937, -0.0437, -0.0987,  0.2391,  0.2676, -0.3876,\n",
       "         0.9132,  0.7786, -0.3593, -0.1810, -1.0035, -1.1220, -0.5471,  0.9383,\n",
       "        -0.9157,  0.2677, -0.0436,  0.3239,  0.2225,  0.7437,  0.0334,  0.9020],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi = 0\n",
    "\n",
    "edge_nt = torch.stack((\n",
    "    edge_index[bi][0][edge_index[bi][0] < self.node_num], # source\n",
    "    edge_index[bi][1][edge_index[bi][1] >= self.node_num] # target\n",
    "    ))\n",
    "edge_tn = torch.stack((\n",
    "    edge_index[bi][0][edge_index[bi][0] >= self.node_num],\n",
    "    edge_index[bi][1][edge_index[bi][1] < self.node_num]\n",
    "    ))               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
