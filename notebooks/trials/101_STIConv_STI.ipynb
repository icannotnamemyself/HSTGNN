{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from enum import Enum\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import signal\n",
    "import threading\n",
    "import time\n",
    "import hashlib\n",
    "from prettytable import PrettyTable\n",
    "import sys\n",
    "####\n",
    "from typing import Dict, List, Type, Union\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchmetrics import MeanSquaredError, MetricCollection, MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from torch_timeseries.data.scaler import *\n",
    "from torch_timeseries.datasets import *\n",
    "from torch_timeseries.experiments.experiment import Experiment\n",
    "\n",
    "from torch_timeseries.datasets.dataset import TimeSeriesDataset\n",
    "from torch_timeseries.datasets.splitter import SequenceRandomSplitter, SequenceSplitter\n",
    "from torch_timeseries.datasets.dataloader import (\n",
    "    ChunkSequenceTimefeatureDataLoader,\n",
    "    DDPChunkSequenceTimefeatureDataLoader,\n",
    ")\n",
    "from torch_timeseries.datasets.wrapper import MultiStepTimeFeatureSet\n",
    "from torch_timeseries.models.Informer import Informer\n",
    "from torch.nn import MSELoss, L1Loss\n",
    "\n",
    "from torch.optim import Optimizer, Adam\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, Subset\n",
    "\n",
    "from torch.nn import DataParallel\n",
    "import torch.nn as nn\n",
    "from dataclasses import asdict,dataclass\n",
    "\n",
    "from torch_timeseries.nn.metric import R2, Corr, TrendAcc,RMSE, compute_corr, compute_r2\n",
    "from torch_timeseries.metrics.masked_mape import MaskedMAPE\n",
    "from torch_timeseries.utils.early_stopping import EarlyStopping\n",
    "import json\n",
    "import codecs\n",
    "\n",
    "\n",
    "from torch_timeseries.layers.tcn_output8 import TCNOuputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import numbers\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class PaddedDilatedInceptionT(nn.Module):\n",
    "    def __init__(self, cin, dilation_factor=2, kernel_set=[2,3,6,7]):\n",
    "        super(PaddedDilatedInceptionT, self).__init__()\n",
    "        self.tconv = nn.ModuleList()\n",
    "        self.kernel_set = kernel_set\n",
    "        # cout = int(cout/len(self.kernel_set))\n",
    "        # assert cout > 0\n",
    "        \n",
    "        for kern in self.kernel_set:\n",
    "            self.tconv.append(nn.Conv2d(cin,cin,(1,kern),dilation=(1,dilation_factor)))\n",
    "\n",
    "    def forward(self,input):\n",
    "\n",
    "        # input: (B, C, N, T)\n",
    "        (B, C, N, T) = input.size()\n",
    "        x = []\n",
    "        for i in range(len(self.kernel_set)):\n",
    "            d_out = self.tconv[i](input)\n",
    "            di = F.pad(d_out, (0, T - d_out.size(3)))\n",
    "            x.append(di) # (B, C, N, T)\n",
    "            \n",
    "        # for i in range(len(self.kernel_set)):\n",
    "        #     x[i] = x[i][...,-x[-1].size(3):]\n",
    "        x = torch.cat(x,dim=1) # (B, k*C, N, T)\n",
    "        return x\n",
    "    \n",
    "class PaddedDilatedInceptionS(nn.Module):\n",
    "    def __init__(self, cin, dilation_factor=2, kernel_set=[2,3,6,7]):\n",
    "        super(PaddedDilatedInceptionS, self).__init__()\n",
    "        self.tconv = nn.ModuleList()\n",
    "        self.kernel_set = kernel_set\n",
    "        # cout = int(cout/len(self.kernel_set))\n",
    "        # assert cout > 0\n",
    "        \n",
    "        for kern in self.kernel_set:\n",
    "            self.tconv.append(nn.Conv2d(cin,cin,(kern,1),dilation=(1,dilation_factor)))\n",
    "\n",
    "    def forward(self,input):\n",
    "\n",
    "        # input: (B, C, N, T)\n",
    "        (B, C, N, T) = input.size()\n",
    "        x = []\n",
    "        for i in range(len(self.kernel_set)):\n",
    "            d_out = self.tconv[i](input)\n",
    "            di = F.pad(d_out, (0, 0,0, N - d_out.size(2)))\n",
    "            x.append(di) # (B, C, N, T)\n",
    "            \n",
    "        # for i in range(len(self.kernel_set)):\n",
    "        #     x[i] = x[i][...,-x[-1].size(3):]\n",
    "        x = torch.cat(x,dim=1) # (B, k*C, N, T)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "B = 32\n",
    "C = 16\n",
    "T = 168\n",
    "N= 90\n",
    "\n",
    "input1 = torch.randn((B, C, N, T),)\n",
    "    \n",
    "t = PaddedDilatedInceptionT(C)\n",
    "s = PaddedDilatedInceptionS(C)\n",
    "\n",
    "# t(input1).shape, s(input1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "class DilatedTTInception(nn.Module):\n",
    "    def __init__(self, cin, N, T, dilation_factor=2, kernel_set=[2,3,6,7]):\n",
    "        super(DilatedTTInception, self).__init__()\n",
    "        \n",
    "\n",
    "        self.out_conv = nn.Conv2d(cin*len(kernel_set), cin, (1,1))\n",
    "        \n",
    "        self.filter_conv = PaddedDilatedInceptionT(cin, dilation_factor, kernel_set)\n",
    "        self.gate_conv = PaddedDilatedInceptionT(cin, dilation_factor, kernel_set)\n",
    "        self.layer_norm = nn.LayerNorm([cin , N, T])\n",
    "        \n",
    "    \n",
    "    \n",
    "    def forward(self, input_x):\n",
    "        filter = self.filter_conv(input_x)\n",
    "        gate = self.gate_conv(input_x)\n",
    "        x = torch.sigmoid(filter) * torch.tanh(gate)\n",
    "        x = self.out_conv(x)\n",
    "        x = x + input_x\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "class DilatedSSInception(nn.Module):\n",
    "    def __init__(self, cin, N, T, dilation_factor=2, kernel_set=[2,3,6,7]):\n",
    "        super(DilatedSSInception, self).__init__()\n",
    "        \n",
    "\n",
    "        self.out_conv = nn.Conv2d(cin*len(kernel_set), cin, (1,1))\n",
    "        \n",
    "        self.filter_conv = PaddedDilatedInceptionS(cin, dilation_factor, kernel_set)\n",
    "        self.gate_conv = PaddedDilatedInceptionS(cin, dilation_factor, kernel_set)\n",
    "        self.layer_norm = nn.LayerNorm([cin , N, T])\n",
    "        \n",
    "    \n",
    "    \n",
    "    def forward(self, input_x):\n",
    "        filter = self.filter_conv(input_x)\n",
    "        gate = self.gate_conv(input_x)\n",
    "        x = torch.sigmoid(filter) * torch.tanh(gate)\n",
    "        x = self.out_conv(x)\n",
    "        x = x + input_x\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "        \n",
    "class DilatedTSInception(nn.Module):\n",
    "    def __init__(self, cin, N, T, dilation_factor=2, kernel_set=[2,3,6,7]):\n",
    "        super(DilatedTSInception, self).__init__()\n",
    "        \n",
    "\n",
    "        self.out_conv = nn.Conv2d(cin*len(kernel_set), cin, (1,1))\n",
    "        \n",
    "        self.filter_conv = PaddedDilatedInceptionT(cin, dilation_factor, kernel_set)\n",
    "        self.gate_conv = PaddedDilatedInceptionS(cin, dilation_factor, kernel_set)\n",
    "        self.layer_norm = nn.LayerNorm([cin , N, T])\n",
    "        \n",
    "    \n",
    "    def forward(self, filter_x, gate_x):\n",
    "        filter = self.filter_conv(filter_x)\n",
    "        gate = self.gate_conv(gate_x)\n",
    "        x = torch.tanh(filter) * torch.sigmoid(gate)\n",
    "        x = self.out_conv(x)\n",
    "        x = x + filter_x\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "class DilatedSTInception(nn.Module):\n",
    "    def __init__(self, cin, N, T, dilation_factor=2, kernel_set=[2,3,6,7]):\n",
    "        super(DilatedSTInception, self).__init__()\n",
    "        \n",
    "\n",
    "        self.out_conv = nn.Conv2d(cin*len(kernel_set), cin, (1,1))\n",
    "        \n",
    "        self.filter_conv = PaddedDilatedInceptionS(cin, dilation_factor, kernel_set)\n",
    "        self.gate_conv = PaddedDilatedInceptionT(cin, dilation_factor, kernel_set)\n",
    "        self.layer_norm = nn.LayerNorm([cin , N, T])\n",
    "        \n",
    "    \n",
    "    def forward(self, filter_x, gate_x):\n",
    "        filter = self.filter_conv(filter_x)\n",
    "        gate = self.gate_conv(gate_x)\n",
    "        x = torch.tanh(filter) * torch.sigmoid(gate)\n",
    "        x = self.out_conv(x)\n",
    "        x = x + filter_x\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "class STMixedConv(nn.Module):\n",
    "    def __init__(self, cin, N, T, dilation_factor=2, kernel_set=[2,3,6,7]) -> None:\n",
    "        super(STMixedConv, self).__init__()\n",
    "        \n",
    "        self.out_conv = nn.Conv2d(cin*4, cin, (1,1))\n",
    "\n",
    "        self.tt_inception = DilatedTTInception(cin, N, T, dilation_factor=dilation_factor, kernel_set=kernel_set)\n",
    "        self.ss_inception = DilatedSSInception(cin, N, T, dilation_factor=dilation_factor, kernel_set=kernel_set)\n",
    "        self.ts_inception = DilatedTSInception(cin, N, T, dilation_factor=dilation_factor, kernel_set=kernel_set)\n",
    "        self.st_inception = DilatedSTInception(cin, N, T, dilation_factor=dilation_factor, kernel_set=kernel_set)\n",
    "        \n",
    "        \n",
    "    def forward(self, input_x):\n",
    "        # input_x : (B, C, N, T)\n",
    "        t_out = self.tt_inception(input_x)\n",
    "        s_out = self.ss_inception(input_x)\n",
    "        \n",
    "        \n",
    "        ts = self.ts_inception(t_out, s_out)\n",
    "        st = self.st_inception(s_out, t_out)\n",
    "        \n",
    "        all_out = torch.concat([t_out, s_out, ts, st],1)\n",
    "        out = self.out_conv(all_out)\n",
    "        out = torch.relu(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class STCN(nn.Module):\n",
    "    def __init__(self, N, T, O,  hidden_channel, latent_dim=128, n_layers=3, in_dim=1,out_dim=1, dilation_factor=2, kernel_set=[2,3,6,7]) -> None:\n",
    "        super(STCN, self).__init__()\n",
    "\n",
    "\n",
    "        self.spatial_projection = nn.Sequential(\n",
    "            nn.Linear( T, latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(latent_dim, latent_dim)\n",
    "        )\n",
    "        self.temporal_projection =nn.GRU(\n",
    "            N,latent_dim, batch_first=True\n",
    "        )\n",
    "        \n",
    "        # self.freq_projection = nn.Sequential(\n",
    "        #     nn.Linear(num_nodes, self.tcn_input_dim),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(self.tcn_input_dim, self.tcn_input_dim)\n",
    "        # )\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        self.feature_rebuild = nn.Sequential(\n",
    "            nn.Linear(latent_dim, T),\n",
    "            torch.nn.ELU(),\n",
    "            nn.Linear(T, T),\n",
    "        )\n",
    "\n",
    "        \n",
    "        self.time_rebuild = nn.GRU(latent_dim, N, batch_first=True)\n",
    "        \n",
    "        self.start_conv = nn.Conv2d(in_dim, hidden_channel, (1,1))\n",
    "        self.st_convs = nn.ModuleList()\n",
    "        self.n_layers = n_layers\n",
    "        for i in range(n_layers):\n",
    "            self.st_convs.append(\n",
    "                STMixedConv(hidden_channel, N, T, dilation_factor, kernel_set)\n",
    "            )\n",
    "        self.end_conv = nn.Conv2d(hidden_channel, out_dim, (1, 1 ))\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(T, T), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(T, O)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # x : (B, N, T)\n",
    "        \n",
    "        seq_last = x[:,:,-1:].detach()\n",
    "        x = x - seq_last\n",
    "\n",
    "        Xs = self.spatial_projection(x) # (B, N, latent_dim)\n",
    "        Xt, _ = self.temporal_projection(x.transpose(1, 2)) # (B, T, latent_dim)\n",
    "        # Xf = torch.abs(torch.fft.fft(x, dim=2, norm='forward'))# (B, N, T)\n",
    "        \n",
    "        # Xf = self.freq_projection(Xf.transpose(1,2 ))  # （B, T, latent_dim)\n",
    "        \n",
    "        Zs = self.feature_rebuild(Xs)  # (B, N, T)\n",
    "        Zt, _ = self.time_rebuild(Xt)\n",
    "        Zt = Zt.transpose(1,2) # (B, N, T)\n",
    "        # Zf = self.freq_rebuild(Xf.transpose(1, 2)).transpose(1, 2) # (B, N, tcn_input_dim)\n",
    "        \n",
    "        Z = torch.stack([Zs, Zt, x], dim=1)\n",
    "        \n",
    "        \n",
    "\n",
    "        x = self.start_conv(Z) # (B, C, N, T)\n",
    "        \n",
    "        # skip = x\n",
    "        \n",
    "        for i in range(self.n_layers):\n",
    "            x = self.st_convs[i](x)\n",
    "            \n",
    "            \n",
    "        x = self.end_conv(torch.relu(x))\n",
    "        x = self.mlp(x) # (B , 1, N, O)\n",
    "        \n",
    "        x = (x.squeeze(1)+ seq_last).transpose(1,2)\n",
    "            # skip = skip + x\n",
    "        return x\n",
    "        \n",
    "\n",
    "@dataclass\n",
    "class STCNExperiment(Experiment):\n",
    "    \n",
    "    hidden_channels: int = 16\n",
    "    n_layers : int = 1\n",
    "    dilated_factor : int = 2\n",
    "    latent_dim : int = 16\n",
    "\n",
    "    def _process_one_batch(self, batch_x, batch_y, batch_x_date_enc, batch_y_date_enc):\n",
    "        # inputs:\n",
    "        # batch_x: (B, T, N)\n",
    "        # batch_y: (B, O, N)\n",
    "        # ouputs:\n",
    "        # - pred: (B, N)/(B, O, N)\n",
    "        # - label: (B, N)/(B, O, N)\n",
    "        batch_size = batch_x.size(0)\n",
    "        batch_x = batch_x.to(self.device, dtype=torch.float32)\n",
    "        batch_y = batch_y.to(self.device, dtype=torch.float32)\n",
    "        batch_x_date_enc = batch_x_date_enc.to(self.device).float()\n",
    "        batch_y_date_enc = batch_y_date_enc.to(self.device).float()\n",
    "        batch_x = batch_x.transpose(1,2) # （B, N, T)\n",
    "        \n",
    "        outputs = self.model(batch_x)  # torch.Size([batch_size, num_nodes])\n",
    "        # single step prediction\n",
    "        return outputs, batch_y\n",
    "\n",
    "\n",
    "    def _init_model(self):\n",
    "        self.model = STCN(\n",
    "            self.dataset.num_features,\n",
    "            self.windows,\n",
    "            self.pred_len,\n",
    "            self.hidden_channels,\n",
    "            self.latent_dim,\n",
    "            self.n_layers,\n",
    "            3,\n",
    "            self.pred_len,\n",
    "            self.dilated_factor,\n",
    "            \n",
    "        )\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 90])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = STCN(N, T,3,  C, in_dim=3)\n",
    "input2 = torch.randn((B, N, T))\n",
    "model(input2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /notebooks/pytorch_timeseries/data/solar_AL/solar_AL.txt.gz\n",
      "Extracting /notebooks/pytorch_timeseries/data/solar_AL/solar_AL.txt.gz to /notebooks/pytorch_timeseries/data/solar_AL\n",
      "train steps: 36601\n",
      "val steps: 10321\n",
      "test steps: 5065\n",
      "torch.get_default_dtype() torch.float32\n",
      "Creating running results saving dir: './results/runs/SolarEnergy/w168h24s1/5653879eeddeac0d52a2046e5f502361'.\n",
      "run : 0 in seed: 234\n",
      "+----------------------------------------------------+------------+\n",
      "|                      Modules                       | Parameters |\n",
      "+----------------------------------------------------+------------+\n",
      "|            spatial_projection.0.weight             |    2688    |\n",
      "|             spatial_projection.0.bias              |     16     |\n",
      "|            spatial_projection.2.weight             |    256     |\n",
      "|             spatial_projection.2.bias              |     16     |\n",
      "|          temporal_projection.weight_ih_l0          |    6576    |\n",
      "|          temporal_projection.weight_hh_l0          |    768     |\n",
      "|           temporal_projection.bias_ih_l0           |     48     |\n",
      "|           temporal_projection.bias_hh_l0           |     48     |\n",
      "|              feature_rebuild.0.weight              |    2688    |\n",
      "|               feature_rebuild.0.bias               |    168     |\n",
      "|              feature_rebuild.2.weight              |   28224    |\n",
      "|               feature_rebuild.2.bias               |    168     |\n",
      "|             time_rebuild.weight_ih_l0              |    6576    |\n",
      "|             time_rebuild.weight_hh_l0              |   56307    |\n",
      "|              time_rebuild.bias_ih_l0               |    411     |\n",
      "|              time_rebuild.bias_hh_l0               |    411     |\n",
      "|                 start_conv.weight                  |     12     |\n",
      "|                  start_conv.bias                   |     4      |\n",
      "|             st_convs.0.out_conv.weight             |     64     |\n",
      "|              st_convs.0.out_conv.bias              |     4      |\n",
      "|      st_convs.0.tt_inception.out_conv.weight       |     64     |\n",
      "|       st_convs.0.tt_inception.out_conv.bias        |     4      |\n",
      "| st_convs.0.tt_inception.filter_conv.tconv.0.weight |     32     |\n",
      "|  st_convs.0.tt_inception.filter_conv.tconv.0.bias  |     4      |\n",
      "| st_convs.0.tt_inception.filter_conv.tconv.1.weight |     48     |\n",
      "|  st_convs.0.tt_inception.filter_conv.tconv.1.bias  |     4      |\n",
      "| st_convs.0.tt_inception.filter_conv.tconv.2.weight |     96     |\n",
      "|  st_convs.0.tt_inception.filter_conv.tconv.2.bias  |     4      |\n",
      "| st_convs.0.tt_inception.filter_conv.tconv.3.weight |    112     |\n",
      "|  st_convs.0.tt_inception.filter_conv.tconv.3.bias  |     4      |\n",
      "|  st_convs.0.tt_inception.gate_conv.tconv.0.weight  |     32     |\n",
      "|   st_convs.0.tt_inception.gate_conv.tconv.0.bias   |     4      |\n",
      "|  st_convs.0.tt_inception.gate_conv.tconv.1.weight  |     48     |\n",
      "|   st_convs.0.tt_inception.gate_conv.tconv.1.bias   |     4      |\n",
      "|  st_convs.0.tt_inception.gate_conv.tconv.2.weight  |     96     |\n",
      "|   st_convs.0.tt_inception.gate_conv.tconv.2.bias   |     4      |\n",
      "|  st_convs.0.tt_inception.gate_conv.tconv.3.weight  |    112     |\n",
      "|   st_convs.0.tt_inception.gate_conv.tconv.3.bias   |     4      |\n",
      "|     st_convs.0.tt_inception.layer_norm.weight      |   92064    |\n",
      "|      st_convs.0.tt_inception.layer_norm.bias       |   92064    |\n",
      "|      st_convs.0.ss_inception.out_conv.weight       |     64     |\n",
      "|       st_convs.0.ss_inception.out_conv.bias        |     4      |\n",
      "| st_convs.0.ss_inception.filter_conv.tconv.0.weight |     32     |\n",
      "|  st_convs.0.ss_inception.filter_conv.tconv.0.bias  |     4      |\n",
      "| st_convs.0.ss_inception.filter_conv.tconv.1.weight |     48     |\n",
      "|  st_convs.0.ss_inception.filter_conv.tconv.1.bias  |     4      |\n",
      "| st_convs.0.ss_inception.filter_conv.tconv.2.weight |     96     |\n",
      "|  st_convs.0.ss_inception.filter_conv.tconv.2.bias  |     4      |\n",
      "| st_convs.0.ss_inception.filter_conv.tconv.3.weight |    112     |\n",
      "|  st_convs.0.ss_inception.filter_conv.tconv.3.bias  |     4      |\n",
      "|  st_convs.0.ss_inception.gate_conv.tconv.0.weight  |     32     |\n",
      "|   st_convs.0.ss_inception.gate_conv.tconv.0.bias   |     4      |\n",
      "|  st_convs.0.ss_inception.gate_conv.tconv.1.weight  |     48     |\n",
      "|   st_convs.0.ss_inception.gate_conv.tconv.1.bias   |     4      |\n",
      "|  st_convs.0.ss_inception.gate_conv.tconv.2.weight  |     96     |\n",
      "|   st_convs.0.ss_inception.gate_conv.tconv.2.bias   |     4      |\n",
      "|  st_convs.0.ss_inception.gate_conv.tconv.3.weight  |    112     |\n",
      "|   st_convs.0.ss_inception.gate_conv.tconv.3.bias   |     4      |\n",
      "|     st_convs.0.ss_inception.layer_norm.weight      |   92064    |\n",
      "|      st_convs.0.ss_inception.layer_norm.bias       |   92064    |\n",
      "|      st_convs.0.ts_inception.out_conv.weight       |     64     |\n",
      "|       st_convs.0.ts_inception.out_conv.bias        |     4      |\n",
      "| st_convs.0.ts_inception.filter_conv.tconv.0.weight |     32     |\n",
      "|  st_convs.0.ts_inception.filter_conv.tconv.0.bias  |     4      |\n",
      "| st_convs.0.ts_inception.filter_conv.tconv.1.weight |     48     |\n",
      "|  st_convs.0.ts_inception.filter_conv.tconv.1.bias  |     4      |\n",
      "| st_convs.0.ts_inception.filter_conv.tconv.2.weight |     96     |\n",
      "|  st_convs.0.ts_inception.filter_conv.tconv.2.bias  |     4      |\n",
      "| st_convs.0.ts_inception.filter_conv.tconv.3.weight |    112     |\n",
      "|  st_convs.0.ts_inception.filter_conv.tconv.3.bias  |     4      |\n",
      "|  st_convs.0.ts_inception.gate_conv.tconv.0.weight  |     32     |\n",
      "|   st_convs.0.ts_inception.gate_conv.tconv.0.bias   |     4      |\n",
      "|  st_convs.0.ts_inception.gate_conv.tconv.1.weight  |     48     |\n",
      "|   st_convs.0.ts_inception.gate_conv.tconv.1.bias   |     4      |\n",
      "|  st_convs.0.ts_inception.gate_conv.tconv.2.weight  |     96     |\n",
      "|   st_convs.0.ts_inception.gate_conv.tconv.2.bias   |     4      |\n",
      "|  st_convs.0.ts_inception.gate_conv.tconv.3.weight  |    112     |\n",
      "|   st_convs.0.ts_inception.gate_conv.tconv.3.bias   |     4      |\n",
      "|     st_convs.0.ts_inception.layer_norm.weight      |   92064    |\n",
      "|      st_convs.0.ts_inception.layer_norm.bias       |   92064    |\n",
      "|      st_convs.0.st_inception.out_conv.weight       |     64     |\n",
      "|       st_convs.0.st_inception.out_conv.bias        |     4      |\n",
      "| st_convs.0.st_inception.filter_conv.tconv.0.weight |     32     |\n",
      "|  st_convs.0.st_inception.filter_conv.tconv.0.bias  |     4      |\n",
      "| st_convs.0.st_inception.filter_conv.tconv.1.weight |     48     |\n",
      "|  st_convs.0.st_inception.filter_conv.tconv.1.bias  |     4      |\n",
      "| st_convs.0.st_inception.filter_conv.tconv.2.weight |     96     |\n",
      "|  st_convs.0.st_inception.filter_conv.tconv.2.bias  |     4      |\n",
      "| st_convs.0.st_inception.filter_conv.tconv.3.weight |    112     |\n",
      "|  st_convs.0.st_inception.filter_conv.tconv.3.bias  |     4      |\n",
      "|  st_convs.0.st_inception.gate_conv.tconv.0.weight  |     32     |\n",
      "|   st_convs.0.st_inception.gate_conv.tconv.0.bias   |     4      |\n",
      "|  st_convs.0.st_inception.gate_conv.tconv.1.weight  |     48     |\n",
      "|   st_convs.0.st_inception.gate_conv.tconv.1.bias   |     4      |\n",
      "|  st_convs.0.st_inception.gate_conv.tconv.2.weight  |     96     |\n",
      "|   st_convs.0.st_inception.gate_conv.tconv.2.bias   |     4      |\n",
      "|  st_convs.0.st_inception.gate_conv.tconv.3.weight  |    112     |\n",
      "|   st_convs.0.st_inception.gate_conv.tconv.3.bias   |     4      |\n",
      "|     st_convs.0.st_inception.layer_norm.weight      |   92064    |\n",
      "|      st_convs.0.st_inception.layer_norm.bias       |   92064    |\n",
      "|             st_convs.1.out_conv.weight             |     64     |\n",
      "|              st_convs.1.out_conv.bias              |     4      |\n",
      "|      st_convs.1.tt_inception.out_conv.weight       |     64     |\n",
      "|       st_convs.1.tt_inception.out_conv.bias        |     4      |\n",
      "| st_convs.1.tt_inception.filter_conv.tconv.0.weight |     32     |\n",
      "|  st_convs.1.tt_inception.filter_conv.tconv.0.bias  |     4      |\n",
      "| st_convs.1.tt_inception.filter_conv.tconv.1.weight |     48     |\n",
      "|  st_convs.1.tt_inception.filter_conv.tconv.1.bias  |     4      |\n",
      "| st_convs.1.tt_inception.filter_conv.tconv.2.weight |     96     |\n",
      "|  st_convs.1.tt_inception.filter_conv.tconv.2.bias  |     4      |\n",
      "| st_convs.1.tt_inception.filter_conv.tconv.3.weight |    112     |\n",
      "|  st_convs.1.tt_inception.filter_conv.tconv.3.bias  |     4      |\n",
      "|  st_convs.1.tt_inception.gate_conv.tconv.0.weight  |     32     |\n",
      "|   st_convs.1.tt_inception.gate_conv.tconv.0.bias   |     4      |\n",
      "|  st_convs.1.tt_inception.gate_conv.tconv.1.weight  |     48     |\n",
      "|   st_convs.1.tt_inception.gate_conv.tconv.1.bias   |     4      |\n",
      "|  st_convs.1.tt_inception.gate_conv.tconv.2.weight  |     96     |\n",
      "|   st_convs.1.tt_inception.gate_conv.tconv.2.bias   |     4      |\n",
      "|  st_convs.1.tt_inception.gate_conv.tconv.3.weight  |    112     |\n",
      "|   st_convs.1.tt_inception.gate_conv.tconv.3.bias   |     4      |\n",
      "|     st_convs.1.tt_inception.layer_norm.weight      |   92064    |\n",
      "|      st_convs.1.tt_inception.layer_norm.bias       |   92064    |\n",
      "|      st_convs.1.ss_inception.out_conv.weight       |     64     |\n",
      "|       st_convs.1.ss_inception.out_conv.bias        |     4      |\n",
      "| st_convs.1.ss_inception.filter_conv.tconv.0.weight |     32     |\n",
      "|  st_convs.1.ss_inception.filter_conv.tconv.0.bias  |     4      |\n",
      "| st_convs.1.ss_inception.filter_conv.tconv.1.weight |     48     |\n",
      "|  st_convs.1.ss_inception.filter_conv.tconv.1.bias  |     4      |\n",
      "| st_convs.1.ss_inception.filter_conv.tconv.2.weight |     96     |\n",
      "|  st_convs.1.ss_inception.filter_conv.tconv.2.bias  |     4      |\n",
      "| st_convs.1.ss_inception.filter_conv.tconv.3.weight |    112     |\n",
      "|  st_convs.1.ss_inception.filter_conv.tconv.3.bias  |     4      |\n",
      "|  st_convs.1.ss_inception.gate_conv.tconv.0.weight  |     32     |\n",
      "|   st_convs.1.ss_inception.gate_conv.tconv.0.bias   |     4      |\n",
      "|  st_convs.1.ss_inception.gate_conv.tconv.1.weight  |     48     |\n",
      "|   st_convs.1.ss_inception.gate_conv.tconv.1.bias   |     4      |\n",
      "|  st_convs.1.ss_inception.gate_conv.tconv.2.weight  |     96     |\n",
      "|   st_convs.1.ss_inception.gate_conv.tconv.2.bias   |     4      |\n",
      "|  st_convs.1.ss_inception.gate_conv.tconv.3.weight  |    112     |\n",
      "|   st_convs.1.ss_inception.gate_conv.tconv.3.bias   |     4      |\n",
      "|     st_convs.1.ss_inception.layer_norm.weight      |   92064    |\n",
      "|      st_convs.1.ss_inception.layer_norm.bias       |   92064    |\n",
      "|      st_convs.1.ts_inception.out_conv.weight       |     64     |\n",
      "|       st_convs.1.ts_inception.out_conv.bias        |     4      |\n",
      "| st_convs.1.ts_inception.filter_conv.tconv.0.weight |     32     |\n",
      "|  st_convs.1.ts_inception.filter_conv.tconv.0.bias  |     4      |\n",
      "| st_convs.1.ts_inception.filter_conv.tconv.1.weight |     48     |\n",
      "|  st_convs.1.ts_inception.filter_conv.tconv.1.bias  |     4      |\n",
      "| st_convs.1.ts_inception.filter_conv.tconv.2.weight |     96     |\n",
      "|  st_convs.1.ts_inception.filter_conv.tconv.2.bias  |     4      |\n",
      "| st_convs.1.ts_inception.filter_conv.tconv.3.weight |    112     |\n",
      "|  st_convs.1.ts_inception.filter_conv.tconv.3.bias  |     4      |\n",
      "|  st_convs.1.ts_inception.gate_conv.tconv.0.weight  |     32     |\n",
      "|   st_convs.1.ts_inception.gate_conv.tconv.0.bias   |     4      |\n",
      "|  st_convs.1.ts_inception.gate_conv.tconv.1.weight  |     48     |\n",
      "|   st_convs.1.ts_inception.gate_conv.tconv.1.bias   |     4      |\n",
      "|  st_convs.1.ts_inception.gate_conv.tconv.2.weight  |     96     |\n",
      "|   st_convs.1.ts_inception.gate_conv.tconv.2.bias   |     4      |\n",
      "|  st_convs.1.ts_inception.gate_conv.tconv.3.weight  |    112     |\n",
      "|   st_convs.1.ts_inception.gate_conv.tconv.3.bias   |     4      |\n",
      "|     st_convs.1.ts_inception.layer_norm.weight      |   92064    |\n",
      "|      st_convs.1.ts_inception.layer_norm.bias       |   92064    |\n",
      "|      st_convs.1.st_inception.out_conv.weight       |     64     |\n",
      "|       st_convs.1.st_inception.out_conv.bias        |     4      |\n",
      "| st_convs.1.st_inception.filter_conv.tconv.0.weight |     32     |\n",
      "|  st_convs.1.st_inception.filter_conv.tconv.0.bias  |     4      |\n",
      "| st_convs.1.st_inception.filter_conv.tconv.1.weight |     48     |\n",
      "|  st_convs.1.st_inception.filter_conv.tconv.1.bias  |     4      |\n",
      "| st_convs.1.st_inception.filter_conv.tconv.2.weight |     96     |\n",
      "|  st_convs.1.st_inception.filter_conv.tconv.2.bias  |     4      |\n",
      "| st_convs.1.st_inception.filter_conv.tconv.3.weight |    112     |\n",
      "|  st_convs.1.st_inception.filter_conv.tconv.3.bias  |     4      |\n",
      "|  st_convs.1.st_inception.gate_conv.tconv.0.weight  |     32     |\n",
      "|   st_convs.1.st_inception.gate_conv.tconv.0.bias   |     4      |\n",
      "|  st_convs.1.st_inception.gate_conv.tconv.1.weight  |     48     |\n",
      "|   st_convs.1.st_inception.gate_conv.tconv.1.bias   |     4      |\n",
      "|  st_convs.1.st_inception.gate_conv.tconv.2.weight  |     96     |\n",
      "|   st_convs.1.st_inception.gate_conv.tconv.2.bias   |     4      |\n",
      "|  st_convs.1.st_inception.gate_conv.tconv.3.weight  |    112     |\n",
      "|   st_convs.1.st_inception.gate_conv.tconv.3.bias   |     4      |\n",
      "|     st_convs.1.st_inception.layer_norm.weight      |   92064    |\n",
      "|      st_convs.1.st_inception.layer_norm.bias       |   92064    |\n",
      "|             st_convs.2.out_conv.weight             |     64     |\n",
      "|              st_convs.2.out_conv.bias              |     4      |\n",
      "|      st_convs.2.tt_inception.out_conv.weight       |     64     |\n",
      "|       st_convs.2.tt_inception.out_conv.bias        |     4      |\n",
      "| st_convs.2.tt_inception.filter_conv.tconv.0.weight |     32     |\n",
      "|  st_convs.2.tt_inception.filter_conv.tconv.0.bias  |     4      |\n",
      "| st_convs.2.tt_inception.filter_conv.tconv.1.weight |     48     |\n",
      "|  st_convs.2.tt_inception.filter_conv.tconv.1.bias  |     4      |\n",
      "| st_convs.2.tt_inception.filter_conv.tconv.2.weight |     96     |\n",
      "|  st_convs.2.tt_inception.filter_conv.tconv.2.bias  |     4      |\n",
      "| st_convs.2.tt_inception.filter_conv.tconv.3.weight |    112     |\n",
      "|  st_convs.2.tt_inception.filter_conv.tconv.3.bias  |     4      |\n",
      "|  st_convs.2.tt_inception.gate_conv.tconv.0.weight  |     32     |\n",
      "|   st_convs.2.tt_inception.gate_conv.tconv.0.bias   |     4      |\n",
      "|  st_convs.2.tt_inception.gate_conv.tconv.1.weight  |     48     |\n",
      "|   st_convs.2.tt_inception.gate_conv.tconv.1.bias   |     4      |\n",
      "|  st_convs.2.tt_inception.gate_conv.tconv.2.weight  |     96     |\n",
      "|   st_convs.2.tt_inception.gate_conv.tconv.2.bias   |     4      |\n",
      "|  st_convs.2.tt_inception.gate_conv.tconv.3.weight  |    112     |\n",
      "|   st_convs.2.tt_inception.gate_conv.tconv.3.bias   |     4      |\n",
      "|     st_convs.2.tt_inception.layer_norm.weight      |   92064    |\n",
      "|      st_convs.2.tt_inception.layer_norm.bias       |   92064    |\n",
      "|      st_convs.2.ss_inception.out_conv.weight       |     64     |\n",
      "|       st_convs.2.ss_inception.out_conv.bias        |     4      |\n",
      "| st_convs.2.ss_inception.filter_conv.tconv.0.weight |     32     |\n",
      "|  st_convs.2.ss_inception.filter_conv.tconv.0.bias  |     4      |\n",
      "| st_convs.2.ss_inception.filter_conv.tconv.1.weight |     48     |\n",
      "|  st_convs.2.ss_inception.filter_conv.tconv.1.bias  |     4      |\n",
      "| st_convs.2.ss_inception.filter_conv.tconv.2.weight |     96     |\n",
      "|  st_convs.2.ss_inception.filter_conv.tconv.2.bias  |     4      |\n",
      "| st_convs.2.ss_inception.filter_conv.tconv.3.weight |    112     |\n",
      "|  st_convs.2.ss_inception.filter_conv.tconv.3.bias  |     4      |\n",
      "|  st_convs.2.ss_inception.gate_conv.tconv.0.weight  |     32     |\n",
      "|   st_convs.2.ss_inception.gate_conv.tconv.0.bias   |     4      |\n",
      "|  st_convs.2.ss_inception.gate_conv.tconv.1.weight  |     48     |\n",
      "|   st_convs.2.ss_inception.gate_conv.tconv.1.bias   |     4      |\n",
      "|  st_convs.2.ss_inception.gate_conv.tconv.2.weight  |     96     |\n",
      "|   st_convs.2.ss_inception.gate_conv.tconv.2.bias   |     4      |\n",
      "|  st_convs.2.ss_inception.gate_conv.tconv.3.weight  |    112     |\n",
      "|   st_convs.2.ss_inception.gate_conv.tconv.3.bias   |     4      |\n",
      "|     st_convs.2.ss_inception.layer_norm.weight      |   92064    |\n",
      "|      st_convs.2.ss_inception.layer_norm.bias       |   92064    |\n",
      "|      st_convs.2.ts_inception.out_conv.weight       |     64     |\n",
      "|       st_convs.2.ts_inception.out_conv.bias        |     4      |\n",
      "| st_convs.2.ts_inception.filter_conv.tconv.0.weight |     32     |\n",
      "|  st_convs.2.ts_inception.filter_conv.tconv.0.bias  |     4      |\n",
      "| st_convs.2.ts_inception.filter_conv.tconv.1.weight |     48     |\n",
      "|  st_convs.2.ts_inception.filter_conv.tconv.1.bias  |     4      |\n",
      "| st_convs.2.ts_inception.filter_conv.tconv.2.weight |     96     |\n",
      "|  st_convs.2.ts_inception.filter_conv.tconv.2.bias  |     4      |\n",
      "| st_convs.2.ts_inception.filter_conv.tconv.3.weight |    112     |\n",
      "|  st_convs.2.ts_inception.filter_conv.tconv.3.bias  |     4      |\n",
      "|  st_convs.2.ts_inception.gate_conv.tconv.0.weight  |     32     |\n",
      "|   st_convs.2.ts_inception.gate_conv.tconv.0.bias   |     4      |\n",
      "|  st_convs.2.ts_inception.gate_conv.tconv.1.weight  |     48     |\n",
      "|   st_convs.2.ts_inception.gate_conv.tconv.1.bias   |     4      |\n",
      "|  st_convs.2.ts_inception.gate_conv.tconv.2.weight  |     96     |\n",
      "|   st_convs.2.ts_inception.gate_conv.tconv.2.bias   |     4      |\n",
      "|  st_convs.2.ts_inception.gate_conv.tconv.3.weight  |    112     |\n",
      "|   st_convs.2.ts_inception.gate_conv.tconv.3.bias   |     4      |\n",
      "|     st_convs.2.ts_inception.layer_norm.weight      |   92064    |\n",
      "|      st_convs.2.ts_inception.layer_norm.bias       |   92064    |\n",
      "|      st_convs.2.st_inception.out_conv.weight       |     64     |\n",
      "|       st_convs.2.st_inception.out_conv.bias        |     4      |\n",
      "| st_convs.2.st_inception.filter_conv.tconv.0.weight |     32     |\n",
      "|  st_convs.2.st_inception.filter_conv.tconv.0.bias  |     4      |\n",
      "| st_convs.2.st_inception.filter_conv.tconv.1.weight |     48     |\n",
      "|  st_convs.2.st_inception.filter_conv.tconv.1.bias  |     4      |\n",
      "| st_convs.2.st_inception.filter_conv.tconv.2.weight |     96     |\n",
      "|  st_convs.2.st_inception.filter_conv.tconv.2.bias  |     4      |\n",
      "| st_convs.2.st_inception.filter_conv.tconv.3.weight |    112     |\n",
      "|  st_convs.2.st_inception.filter_conv.tconv.3.bias  |     4      |\n",
      "|  st_convs.2.st_inception.gate_conv.tconv.0.weight  |     32     |\n",
      "|   st_convs.2.st_inception.gate_conv.tconv.0.bias   |     4      |\n",
      "|  st_convs.2.st_inception.gate_conv.tconv.1.weight  |     48     |\n",
      "|   st_convs.2.st_inception.gate_conv.tconv.1.bias   |     4      |\n",
      "|  st_convs.2.st_inception.gate_conv.tconv.2.weight  |     96     |\n",
      "|   st_convs.2.st_inception.gate_conv.tconv.2.bias   |     4      |\n",
      "|  st_convs.2.st_inception.gate_conv.tconv.3.weight  |    112     |\n",
      "|   st_convs.2.st_inception.gate_conv.tconv.3.bias   |     4      |\n",
      "|     st_convs.2.st_inception.layer_norm.weight      |   92064    |\n",
      "|      st_convs.2.st_inception.layer_norm.bias       |   92064    |\n",
      "|                  end_conv.weight                   |     4      |\n",
      "|                   end_conv.bias                    |     1      |\n",
      "|                    mlp.0.weight                    |   28224    |\n",
      "|                     mlp.0.bias                     |    168     |\n",
      "|                    mlp.2.weight                    |    168     |\n",
      "|                     mlp.2.bias                     |     1      |\n",
      "+----------------------------------------------------+------------+\n",
      "Total Trainable Params: 2351803\n",
      "model parameters: 2351803\n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36601/36601 [04:34<00:00, 133.10it/s, epoch=0, loss=0.0914, lr=0.0003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost time: 275.0020716190338\n",
      "Traininng loss : 0.20994998700916767\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10321/10321 [00:30<00:00, 341.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.3775153160095215, 'mae': 0.22028812766075134, 'mse': 0.14802412688732147, 'r2': 0.8423250317573547, 'r2_weighted': 0.8427611589431763}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5065/5065 [00:15<00:00, 322.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.31939759850502014, 'mae': 0.22899308800697327, 'mse': 0.15650640428066254, 'r2': 0.7610507607460022, 'r2_weighted': 0.7635198831558228}\n",
      "Validation loss decreased (inf --> 0.148024).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/SolarEnergy/w168h24s1/5653879eeddeac0d52a2046e5f502361'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36601/36601 [04:33<00:00, 133.74it/s, epoch=1, loss=0.167, lr=0.0003] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 cost time: 594.8347315788269\n",
      "Traininng loss : 0.14914005703025765\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10321/10321 [00:29<00:00, 350.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.27678728103637695, 'mae': 0.22768355906009674, 'mse': 0.14584636688232422, 'r2': 0.844618022441864, 'r2_weighted': 0.8450745344161987}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5065/5065 [00:16<00:00, 311.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.1825583428144455, 'mae': 0.2417413890361786, 'mse': 0.1549934297800064, 'r2': 0.7632052302360535, 'r2_weighted': 0.7658059597015381}\n",
      "Validation loss decreased (0.148024 --> 0.145846).  Saving model ...\n",
      "Saving run checkpoint to './results/runs/SolarEnergy/w168h24s1/5653879eeddeac0d52a2046e5f502361'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36601/36601 [04:30<00:00, 135.50it/s, epoch=2, loss=0.226, lr=0.0003] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 cost time: 910.949385881424\n",
      "Traininng loss : 0.1422859501627671\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10321/10321 [00:27<00:00, 371.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.4074137210845947, 'mae': 0.24390935897827148, 'mse': 0.15038971602916718, 'r2': 0.8397960066795349, 'r2_weighted': 0.840248167514801}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5065/5065 [00:15<00:00, 325.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.3453538715839386, 'mae': 0.24903534352779388, 'mse': 0.1547049731016159, 'r2': 0.764063835144043, 'r2_weighted': 0.7662417888641357}\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Saving run checkpoint to './results/runs/SolarEnergy/w168h24s1/5653879eeddeac0d52a2046e5f502361'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36601/36601 [04:22<00:00, 139.30it/s, epoch=3, loss=0.156, lr=0.000299] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 cost time: 1217.2029941082\n",
      "Traininng loss : 0.13797226795679204\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10321/10321 [00:30<00:00, 341.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.42725977301597595, 'mae': 0.21580471098423004, 'mse': 0.1535366028547287, 'r2': 0.8366211652755737, 'r2_weighted': 0.8369054794311523}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5065/5065 [00:15<00:00, 318.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.40604981780052185, 'mae': 0.21351811289787292, 'mse': 0.15183526277542114, 'r2': 0.7697080373764038, 'r2_weighted': 0.7705779671669006}\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Saving run checkpoint to './results/runs/SolarEnergy/w168h24s1/5653879eeddeac0d52a2046e5f502361'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36601/36601 [04:34<00:00, 133.58it/s, epoch=4, loss=0.061, lr=0.000299] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 cost time: 1537.6035895347595\n",
      "Traininng loss : 0.13608024431021323\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10321/10321 [00:30<00:00, 343.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.43036940693855286, 'mae': 0.21429631114006042, 'mse': 0.1552933305501938, 'r2': 0.8346232771873474, 'r2_weighted': 0.8350394368171692}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5065/5065 [00:16<00:00, 310.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.4058297872543335, 'mae': 0.21331733465194702, 'mse': 0.1536165326833725, 'r2': 0.7658516764640808, 'r2_weighted': 0.7678865194320679}\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Saving run checkpoint to './results/runs/SolarEnergy/w168h24s1/5653879eeddeac0d52a2046e5f502361'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36601/36601 [04:35<00:00, 132.93it/s, epoch=5, loss=0.0878, lr=0.000298]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 cost time: 1859.5271019935608\n",
      "Traininng loss : 0.1307150977403186\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10321/10321 [00:28<00:00, 357.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.42688626050949097, 'mae': 0.22351773083209991, 'mse': 0.15816693007946014, 'r2': 0.8316601514816284, 'r2_weighted': 0.8319869637489319}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5065/5065 [00:16<00:00, 309.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.37635013461112976, 'mae': 0.22961583733558655, 'mse': 0.16661570966243744, 'r2': 0.7473635673522949, 'r2_weighted': 0.7482448220252991}\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Saving run checkpoint to './results/runs/SolarEnergy/w168h24s1/5653879eeddeac0d52a2046e5f502361'.\n",
      "Run state saved ... \n",
      "torch.get_default_dtype() torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36601/36601 [04:29<00:00, 135.67it/s, epoch=6, loss=0.0795, lr=0.000297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 cost time: 2174.6854321956635\n",
      "Traininng loss : 0.12359967287401896\n",
      "Evaluating .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10321/10321 [00:30<00:00, 343.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vali_results: {'corr': 0.05398860201239586, 'mae': 0.2302062213420868, 'mse': 0.16709120571613312, 'r2': 0.8219844102859497, 'r2_weighted': 0.8225070834159851}\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5065/5065 [00:16<00:00, 309.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': -0.018981575965881348, 'mae': 0.23476339876651764, 'mse': 0.17481611669063568, 'r2': 0.7337695956230164, 'r2_weighted': 0.7358540296554565}\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Saving run checkpoint to './results/runs/SolarEnergy/w168h24s1/5653879eeddeac0d52a2046e5f502361'.\n",
      "Run state saved ... \n",
      "loss no decreased for 5 epochs,  early stopping ....\n",
      "Testing .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5065/5065 [00:16<00:00, 314.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results: {'corr': 0.1825583428144455, 'mae': 0.2417413890361786, 'mse': 0.1549934297800064, 'r2': 0.7632052302360535, 'r2_weighted': 0.7658059597015381}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'corr': 0.1825583428144455,\n",
       " 'mae': 0.2417413890361786,\n",
       " 'mse': 0.1549934297800064,\n",
       " 'r2': 0.7632052302360535,\n",
       " 'r2_weighted': 0.7658059597015381}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = STCNExperiment(\n",
    "    hidden_channels=4,\n",
    "    dataset_type=\"SolarEnergy\",\n",
    "    dilated_factor=1,\n",
    "    n_layers=3,\n",
    "    epochs=100,\n",
    "    horizon=24,\n",
    "    windows=168,\n",
    "    device=\"cuda:4\",\n",
    "    data_path='/notebooks/pytorch_timeseries/data/',\n",
    ")\n",
    "# model = STI(168, 128, 9, 1)\n",
    "# out = model(data)\n",
    "\n",
    "exp.run(seed=234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xf = torch.fft.fft(data, dim=2, norm='forward')[:, :, :]\n",
    "amp = torch.abs(Xf)\n",
    "amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3273,  0.1516,  0.0161, -0.8483,  0.0766,  0.7280,  0.6113, -0.0470,\n",
      "         0.9393,  0.6909,  0.0947,  0.8419,  0.1639, -0.1819,  1.0376,  0.0166,\n",
      "        -0.7076,  0.9921,  0.2978, -0.4104, -1.0616,  0.6393,  0.1030,  0.5463,\n",
      "        -0.3269,  0.1066, -0.1008,  0.2158, -0.1032, -0.3987, -0.4024, -0.3123],\n",
      "       grad_fn=<SelectBackward0>) tensor([-0.4796, -0.6486, -1.6920, -1.0470, -0.4733, -0.2575, -0.1732, -0.4943,\n",
      "         0.1441, -0.6750,  0.2937, -0.0437, -0.0987,  0.2391,  0.2676, -0.3876,\n",
      "         0.9132,  0.7786, -0.3593, -0.1810, -1.0035, -1.1220, -0.5471,  0.9383,\n",
      "        -0.9157,  0.2677, -0.0436,  0.3239,  0.2225,  0.7437,  0.0334,  0.9020],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "torch.Size([7, 32]) torch.Size([7, 32])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4796, -0.6486, -1.6920, -1.0470, -0.4733, -0.2575, -0.1732, -0.4943,\n",
       "         0.1441, -0.6750,  0.2937, -0.0437, -0.0987,  0.2391,  0.2676, -0.3876,\n",
       "         0.9132,  0.7786, -0.3593, -0.1810, -1.0035, -1.1220, -0.5471,  0.9383,\n",
       "        -0.9157,  0.2677, -0.0436,  0.3239,  0.2225,  0.7437,  0.0334,  0.9020],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi = 0\n",
    "\n",
    "edge_nt = torch.stack((\n",
    "    edge_index[bi][0][edge_index[bi][0] < self.node_num], # source\n",
    "    edge_index[bi][1][edge_index[bi][1] >= self.node_num] # target\n",
    "    ))\n",
    "edge_tn = torch.stack((\n",
    "    edge_index[bi][0][edge_index[bi][0] >= self.node_num],\n",
    "    edge_index[bi][1][edge_index[bi][1] < self.node_num]\n",
    "    ))               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
