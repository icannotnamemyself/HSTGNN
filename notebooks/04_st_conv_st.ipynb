{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import copy\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from class_resolver.contrib.torch import activation_resolver\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.nn import FAConv,HeteroConv\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "\n",
    "from torch_geometric.nn import HeteroConv, GCNConv, SAGEConv, GATConv, Linear\n",
    "# from torch_timeseries.layers.graphsage import MyGraphSage\n",
    "\n",
    "# from torch_timeseries.utils.norm import hetero_directed_norm\n",
    "\n",
    "def hetero_directed_norm(edge_index, edge_weight=None, num_nodes=None,\n",
    "              dtype=None):\n",
    "\n",
    "    if isinstance(edge_index, SparseTensor):\n",
    "        raise NotImplementedError(\"Operation of Sparse Tensor Not defined!\")\n",
    "    else:\n",
    "        num_nodes = maybe_num_nodes(edge_index, num_nodes)\n",
    "\n",
    "        if edge_weight is None:\n",
    "            edge_weight = torch.ones((edge_index.size(1), ), dtype=dtype,\n",
    "                                     device=edge_index.device)\n",
    "\n",
    "        row, col = edge_index[0], edge_index[1]\n",
    "        \n",
    "        # in degree of every node |N|\n",
    "        in_deg = scatter_add(edge_weight, col, dim=0, dim_size=num_nodes)\n",
    "\n",
    "        # out degree of every node |N|\n",
    "        out_deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n",
    "\n",
    "        # nomalization\n",
    "        in_deg_inv_sqrt = in_deg.pow_(-0.5)\n",
    "        out_deg_inv_sqrt = out_deg.pow_(-0.5)\n",
    "        in_deg_inv_sqrt.masked_fill_(in_deg_inv_sqrt == float('inf'), 0)\n",
    "        out_deg_inv_sqrt.masked_fill_(out_deg_inv_sqrt == float('inf'), 0)\n",
    "\n",
    "        # source node out degree, target node in degree \n",
    "        return out_deg_inv_sqrt[row] * edge_weight * in_deg_inv_sqrt[col]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TSConv(MessagePassing):\n",
    "    # convolution for relation < t -> s >\n",
    "    def __init__(self, in_channels, out_channels, eps=0.9):\n",
    "        super().__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "        self.eps = eps\n",
    "        self.att_g = Linear(2*in_channels,1, bias=False)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        super().reset_parameters()\n",
    "        self.att_g.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        # x has shape [N+T, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "        # edge_index has shape [E, weight_dim]\n",
    "        \n",
    "        xt = x[0]\n",
    "        xs = x[1]\n",
    "        \n",
    "        x = torch.concat([xs, xt], dim=0)\n",
    "        \n",
    "        edge_weight = hetero_directed_norm(  # yapf: disable\n",
    "            edge_index, edge_weight, x.size(self.node_dim), dtype=x.dtype)\n",
    "\n",
    "        t2s_info = self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
    "        \n",
    "        return t2s_info\n",
    "\n",
    "    def message(self,x_i, x_j, edge_weight):\n",
    "        # x_j has shape [|E|, out_channels] , The first n edges are edges of  spatial nodes\n",
    "        # x_j denotes a lifted tensor, which contains the source node features of each edge, source_node(如果flow 是 source_to_target)\n",
    "        # 要从从有向图的角度来解释 edge_index 有几个，就有几个x_\n",
    "        \n",
    "        # 对 st , ts分别定义\n",
    "        \n",
    "        alpha_i_j = self.att_g(torch.concat([x_i, x_j], axis=1)).tanh().squeeze(-1) # ( |E|, )    \n",
    "        \n",
    "        return x_j *( alpha_i_j * edge_weight ).view(-1,1)\n",
    "\n",
    "\n",
    "class STConv(MessagePassing):\n",
    "    # convolution for relation < s -> t >\n",
    "    def __init__(self, in_channels, out_channels, eps=0.9):\n",
    "        super().__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "        self.eps = eps\n",
    "        self.att_g = Linear(2*in_channels,1, bias=False)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        super().reset_parameters()\n",
    "        self.att_g.reset_parameters()\n",
    "        # self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        # x has shape [N+T, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "        # edge_index has shape [E, weight_dim]\n",
    "        xs = x[0]\n",
    "        xt = x[1]\n",
    "        \n",
    "        x = torch.concat([xs, xt], dim=0)\n",
    "        \n",
    "        edge_weight = hetero_directed_norm(  # yapf: disable\n",
    "            edge_index, edge_weight, x.size(self.node_dim), dtype=x.dtype)\n",
    "        s2t_info = self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
    "        return s2t_info\n",
    "\n",
    "    def message(self,x_i, x_j, edge_weight):\n",
    "        # x_j has shape [|E|, out_channels] , The first n edges are edges of  spatial nodes\n",
    "        # x_j denotes a lifted tensor, which contains the source node features of each edge, source_node(如果flow 是 source_to_target)\n",
    "        # 要从从有向图的角度来解释 edge_index 有几个，就有几个x_\n",
    "        \n",
    "        # 对 st , ts分别定义\n",
    "        alpha_i_j = self.att_g(torch.concat([x_i, x_j], axis=1)).tanh().squeeze(-1) # ( |E|, )    \n",
    "        \n",
    "        return x_j *( alpha_i_j * edge_weight ).view(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "class SSConv(MessagePassing):\n",
    "    # convolution for relation < s -> t >\n",
    "    def __init__(self, in_channels, out_channels,add_self_loops=True, eps=0.9):\n",
    "        super().__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "        self.eps = eps\n",
    "        self.att_g = Linear(2*in_channels,1, bias=False)\n",
    "        self.add_self_loops = add_self_loops\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        super().reset_parameters()\n",
    "        self.att_g.reset_parameters()\n",
    "        # self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        # x has shape [N+T, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "        # edge_index has shape [E, weight_dim]\n",
    "        edge_index , edge_weight = gcn_norm(  # yapf: disable\n",
    "            edge_index, edge_weight,add_self_loops=self.add_self_loops,num_nodes=x.size(self.node_dim), dtype=x.dtype)\n",
    "        s2s_info = self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
    "        return s2s_info\n",
    "\n",
    "    def message(self,x_i, x_j, edge_weight):\n",
    "        # x_j has shape [|E|, out_channels] , The first n edges are edges of  spatial nodes\n",
    "        # x_j denotes a lifted tensor, which contains the source node features of each edge, source_node(如果flow 是 source_to_target)\n",
    "        # 要从从有向图的角度来解释 edge_index 有几个，就有几个x_\n",
    "        \n",
    "        # 对 st , ts分别定义\n",
    "        alpha_i_j = self.att_g(torch.concat([x_i, x_j], axis=1)).tanh().squeeze(-1) # ( |E|, )    \n",
    "        \n",
    "        return x_j *( alpha_i_j * edge_weight ).view(-1,1)\n",
    "\n",
    "\n",
    "class TTConv(MessagePassing):\n",
    "    # convolution for relation < s -> t >\n",
    "    def __init__(self, in_channels, out_channels,add_self_loops=True, eps=0.9):\n",
    "        super().__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "        self.eps = eps\n",
    "        self.att_g = Linear(2*in_channels,1, bias=False)\n",
    "        self.add_self_loops = add_self_loops\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        super().reset_parameters()\n",
    "        self.att_g.reset_parameters()\n",
    "        # self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        # x has shape [N+T, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "        # edge_index has shape [E, weight_dim]\n",
    "        \n",
    "        edge_index , edge_weight = gcn_norm(  # yapf: disable\n",
    "            edge_index, edge_weight,add_self_loops=self.add_self_loops,num_nodes=x.size(self.node_dim), dtype=x.dtype)\n",
    "        t2t_info = self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
    "        return t2t_info\n",
    "\n",
    "    def message(self,x_i, x_j, edge_weight):\n",
    "        # x_j has shape [|E|, out_channels] , The first n edges are edges of  spatial nodes\n",
    "        # x_j denotes a lifted tensor, which contains the source node features of each edge, source_node(如果flow 是 source_to_target)\n",
    "        # 要从从有向图的角度来解释 edge_index 有几个，就有几个x_\n",
    "        \n",
    "        # 对 st , ts分别定义\n",
    "        alpha_i_j = self.att_g(torch.concat([x_i, x_j], axis=1)).tanh().squeeze(-1) # ( |E|, )    \n",
    "        \n",
    "        return x_j *( alpha_i_j * edge_weight ).view(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class HeteroFASTGCN(nn.Module):\n",
    "    def __init__(\n",
    "        self,node_num,seq_len, in_channels, hidden_channels, n_layers, out_channels=None,\n",
    "        dropout=0, norm=None, act='relu',n_first=True, act_first=False, eps=0.9, **kwargs\n",
    "    ):\n",
    "        \n",
    "        self.node_num =node_num\n",
    "        self.seq_len = seq_len\n",
    "        self.n_first = n_first\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_layers = n_layers\n",
    "\n",
    "        self.dropout = dropout\n",
    "        self.act = activation_resolver.make(act)\n",
    "        self.act_first = act_first\n",
    "        self.eps = eps\n",
    "\n",
    "        if out_channels is not None:\n",
    "            self.out_channels = out_channels\n",
    "        else:\n",
    "            self.out_channels = hidden_channels\n",
    "            \n",
    "        assert n_layers >= 2 , \"intra and inter conv layers must greater than or equals to 2 \"\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        \n",
    "        self.convs.append(self.init_intra_conv(in_channels, hidden_channels))\n",
    "\n",
    "        for i in range(n_layers - 2):\n",
    "            if i % 2 == 1: # intra_conv\n",
    "                self.convs.append(self.init_intra_conv(in_channels, hidden_channels))\n",
    "            else: # inter conv\n",
    "                self.convs.append(self.init_inter_conv(hidden_channels, hidden_channels))\n",
    "          \n",
    "            \n",
    "        if n_layers % 2 == 1: # intra_conv\n",
    "            self.convs.append(self.init_intra_conv(in_channels, out_channels))\n",
    "        else: # inter conv\n",
    "            self.convs.append(self.init_inter_conv(hidden_channels, out_channels))\n",
    "\n",
    "        self.norms = None\n",
    "        if norm is not None:\n",
    "            self.norms = nn.ModuleList()\n",
    "            for _ in range(n_layers - 1):\n",
    "                self.norms.append(copy.deepcopy(norm))\n",
    "            \n",
    "    def init_intra_conv(self, in_channels, out_channels, **kwargs):\n",
    "        # print(\"init_intra\")\n",
    "        intrast_homo_conv = HeteroConv({\n",
    "            ('s', 's2s', 's'): SSConv(in_channels, out_channels, eps=self.eps),\n",
    "            ('t', 't2t', 't'): TTConv(in_channels, out_channels, eps=self.eps),\n",
    "        }, aggr='sum')\n",
    "        return intrast_homo_conv\n",
    "\n",
    "    def init_inter_conv(self, in_channels, out_channels, **kwargs):\n",
    "        # print(\"init_inter\")\n",
    "        interst_biparte_conv = HeteroConv({\n",
    "            ('s', 's2t', 't'): STConv(in_channels, out_channels, eps=self.eps),\n",
    "            ('t', 't2s', 's'): TSConv(in_channels, out_channels, eps=self.eps),\n",
    "        }, aggr='sum')\n",
    "        return interst_biparte_conv\n",
    "        # return FAConv(in_channels, out_channels, **kwargs)\n",
    "\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        # x: B * (N+T) * C\n",
    "        # edge_index: B,2,2*(N*T)\n",
    "        # edge_attr: B*E or B * (N * T )\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            xs = list()\n",
    "            for bi in range(x.shape[0]):\n",
    "\n",
    "                x_dict = {\n",
    "                    's': x[bi][:self.node_num,:],\n",
    "                    't': x[bi][self.node_num:,:]\n",
    "                }\n",
    "                edge_index_bi = edge_index[bi]\n",
    "                if i % 2 == 0: # intra\n",
    "                    edge_nn = edge_index_bi[:, (edge_index_bi[0] < self.node_num) & (edge_index_bi[1] < self.node_num)]\n",
    "                    edge_tt = edge_index_bi[:, (edge_index_bi[0] >=self.node_num ) & (edge_index_bi[1]  >=self.node_num)]\n",
    "                    \n",
    "                    # set tt edge start index to 0\n",
    "                    edge_tt = edge_tt - self.node_num\n",
    "                    edge_index_dict = {\n",
    "                        ('s', 's2s', 's'): edge_nn,\n",
    "                        ('t', 't2t', 't'): edge_tt,\n",
    "                    }\n",
    "                    out_dict = self.convs[i](x_dict,edge_index_dict )\n",
    "                    xi = x[bi] + torch.concat([out_dict['s'], out_dict['t']], dim=0)\n",
    "                    # print(\"prop intra\")\n",
    "                    \n",
    "                else: # inter\n",
    "                    edge_nt = edge_index_bi[:, (edge_index_bi[0] < self.node_num) & (edge_index_bi[1] >= self.node_num)]\n",
    "                    edge_tn = edge_index_bi[:, (edge_index_bi[0] >= self.node_num) & (edge_index_bi[1] < self.node_num)]        \n",
    "                    edge_index_dict = {\n",
    "                        ('s', 's2t', 't'): edge_nt,\n",
    "                        ('t', 't2s', 's'): edge_tn,\n",
    "                    }\n",
    "                    # print(\"prop inter\")\n",
    "                    \n",
    "                    out_dict = self.convs[i](x_dict,edge_index_dict )\n",
    "                    \n",
    "                    xi = x[bi] + out_dict['s'] + out_dict['t']\n",
    "                # combining spatial and temporal mixed information\n",
    "                \n",
    "                # xi = self.convs[i](x[bi], edge_index[bi])\n",
    "                xs.append(xi)\n",
    "            x = torch.stack(xs)\n",
    "            if i == self.num_layers - 1:\n",
    "                break\n",
    "            \n",
    "            if self.act_first:\n",
    "                x = self.act(x)\n",
    "            if self.norms is not None:\n",
    "                x = self.norms[i](x)\n",
    "            if not self.act_first:\n",
    "                x = self.act(x)\n",
    "            \n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = 2\n",
    "seq_len = 4\n",
    "batch_size = 8\n",
    "\n",
    "xn = torch.randn(n_nodes, 128)\n",
    "xt = torch.randn(seq_len, 128)\n",
    "xi = torch.concat([xn, xt], dim=0)\n",
    "\n",
    "\n",
    "tmp = torch.zeros((n_nodes + seq_len, n_nodes + seq_len)) # (NxT , NxT)\n",
    "tmp[:n_nodes, n_nodes:] = 1\n",
    "tmp[n_nodes:, :n_nodes] = 1\n",
    "tmp[:n_nodes, :n_nodes] = 1\n",
    "tmp[n_nodes:, n_nodes:] = 1\n",
    "tmp = tmp - torch.eye(n_nodes + seq_len,n_nodes + seq_len)\n",
    "edge_index = torch.nonzero(tmp).T\n",
    "# edge_index\n",
    "# [edge_index[0][edge_index[0] < n_nodes],\n",
    "# edge_index[1][edge_index[1] >= n_nodes]]\n",
    "\n",
    "\n",
    "\n",
    "batch_x = xi.expand(batch_size, -1, -1)\n",
    "batch_indices = edge_index.expand(batch_size, -1, -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index_bi  = batch_indices[0]\n",
    "\n",
    "edge_nn = edge_index_bi[:, (edge_index_bi[0] < n_nodes) & (edge_index_bi[1] < n_nodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 0]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_intra\n",
      "init_inter\n",
      "init_intra\n"
     ]
    }
   ],
   "source": [
    "gcn = HeteroFASTGCN(n_nodes,seq_len, in_channels=128, hidden_channels=128, n_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prop intra\n",
      "prop intra\n",
      "prop intra\n",
      "prop intra\n",
      "prop intra\n",
      "prop intra\n",
      "prop intra\n",
      "prop intra\n",
      "prop inter\n",
      "prop inter\n",
      "prop inter\n",
      "prop inter\n",
      "prop inter\n",
      "prop inter\n",
      "prop inter\n",
      "prop inter\n",
      "prop intra\n",
      "prop intra\n",
      "prop intra\n",
      "prop intra\n",
      "prop intra\n",
      "prop intra\n",
      "prop intra\n",
      "prop intra\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000e+00,  3.5309e-01,  0.0000e+00,  ...,  6.5688e-01,\n",
       "          -3.2479e-01,  3.9053e-01],\n",
       "         [ 0.0000e+00, -6.9949e-02,  0.0000e+00,  ..., -1.3013e-01,\n",
       "           7.6174e-01, -7.7367e-02],\n",
       "         [ 0.0000e+00,  7.5263e-02,  1.1883e-01,  ...,  1.4307e-01,\n",
       "           2.5159e-02,  1.3688e+00],\n",
       "         [ 0.0000e+00,  6.2398e-02,  3.7416e-01,  ..., -2.0323e-03,\n",
       "           7.1230e-02, -2.0018e-01],\n",
       "         [ 0.0000e+00, -4.1840e-04, -5.2703e-03,  ...,  7.3938e-01,\n",
       "          -4.8131e-03,  8.9747e-01],\n",
       "         [ 0.0000e+00,  2.2863e-02,  2.2337e-01,  ...,  7.8138e-03,\n",
       "           1.2037e-01,  3.1702e-03]],\n",
       "\n",
       "        [[ 0.0000e+00,  3.5309e-01,  0.0000e+00,  ...,  6.5688e-01,\n",
       "          -3.2479e-01,  3.9053e-01],\n",
       "         [ 0.0000e+00, -6.9949e-02,  0.0000e+00,  ..., -1.3013e-01,\n",
       "           7.6174e-01, -7.7367e-02],\n",
       "         [ 0.0000e+00,  7.5263e-02,  1.1883e-01,  ...,  1.4307e-01,\n",
       "           2.5159e-02,  1.3688e+00],\n",
       "         [ 0.0000e+00,  6.2398e-02,  3.7416e-01,  ..., -2.0323e-03,\n",
       "           7.1230e-02, -2.0018e-01],\n",
       "         [ 0.0000e+00, -4.1840e-04, -5.2703e-03,  ...,  7.3938e-01,\n",
       "          -4.8131e-03,  8.9747e-01],\n",
       "         [ 0.0000e+00,  2.2863e-02,  2.2337e-01,  ...,  7.8138e-03,\n",
       "           1.2037e-01,  3.1702e-03]],\n",
       "\n",
       "        [[ 0.0000e+00,  3.5309e-01,  0.0000e+00,  ...,  6.5688e-01,\n",
       "          -3.2479e-01,  3.9053e-01],\n",
       "         [ 0.0000e+00, -6.9949e-02,  0.0000e+00,  ..., -1.3013e-01,\n",
       "           7.6174e-01, -7.7367e-02],\n",
       "         [ 0.0000e+00,  7.5263e-02,  1.1883e-01,  ...,  1.4307e-01,\n",
       "           2.5159e-02,  1.3688e+00],\n",
       "         [ 0.0000e+00,  6.2398e-02,  3.7416e-01,  ..., -2.0323e-03,\n",
       "           7.1230e-02, -2.0018e-01],\n",
       "         [ 0.0000e+00, -4.1840e-04, -5.2703e-03,  ...,  7.3938e-01,\n",
       "          -4.8131e-03,  8.9747e-01],\n",
       "         [ 0.0000e+00,  2.2863e-02,  2.2337e-01,  ...,  7.8138e-03,\n",
       "           1.2037e-01,  3.1702e-03]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0000e+00,  3.5309e-01,  0.0000e+00,  ...,  6.5688e-01,\n",
       "          -3.2479e-01,  3.9053e-01],\n",
       "         [ 0.0000e+00, -6.9949e-02,  0.0000e+00,  ..., -1.3013e-01,\n",
       "           7.6174e-01, -7.7367e-02],\n",
       "         [ 0.0000e+00,  7.5263e-02,  1.1883e-01,  ...,  1.4307e-01,\n",
       "           2.5159e-02,  1.3688e+00],\n",
       "         [ 0.0000e+00,  6.2398e-02,  3.7416e-01,  ..., -2.0323e-03,\n",
       "           7.1230e-02, -2.0018e-01],\n",
       "         [ 0.0000e+00, -4.1840e-04, -5.2703e-03,  ...,  7.3938e-01,\n",
       "          -4.8131e-03,  8.9747e-01],\n",
       "         [ 0.0000e+00,  2.2863e-02,  2.2337e-01,  ...,  7.8138e-03,\n",
       "           1.2037e-01,  3.1702e-03]],\n",
       "\n",
       "        [[ 0.0000e+00,  3.5309e-01,  0.0000e+00,  ...,  6.5688e-01,\n",
       "          -3.2479e-01,  3.9053e-01],\n",
       "         [ 0.0000e+00, -6.9949e-02,  0.0000e+00,  ..., -1.3013e-01,\n",
       "           7.6174e-01, -7.7367e-02],\n",
       "         [ 0.0000e+00,  7.5263e-02,  1.1883e-01,  ...,  1.4307e-01,\n",
       "           2.5159e-02,  1.3688e+00],\n",
       "         [ 0.0000e+00,  6.2398e-02,  3.7416e-01,  ..., -2.0323e-03,\n",
       "           7.1230e-02, -2.0018e-01],\n",
       "         [ 0.0000e+00, -4.1840e-04, -5.2703e-03,  ...,  7.3938e-01,\n",
       "          -4.8131e-03,  8.9747e-01],\n",
       "         [ 0.0000e+00,  2.2863e-02,  2.2337e-01,  ...,  7.8138e-03,\n",
       "           1.2037e-01,  3.1702e-03]],\n",
       "\n",
       "        [[ 0.0000e+00,  3.5309e-01,  0.0000e+00,  ...,  6.5688e-01,\n",
       "          -3.2479e-01,  3.9053e-01],\n",
       "         [ 0.0000e+00, -6.9949e-02,  0.0000e+00,  ..., -1.3013e-01,\n",
       "           7.6174e-01, -7.7367e-02],\n",
       "         [ 0.0000e+00,  7.5263e-02,  1.1883e-01,  ...,  1.4307e-01,\n",
       "           2.5159e-02,  1.3688e+00],\n",
       "         [ 0.0000e+00,  6.2398e-02,  3.7416e-01,  ..., -2.0323e-03,\n",
       "           7.1230e-02, -2.0018e-01],\n",
       "         [ 0.0000e+00, -4.1840e-04, -5.2703e-03,  ...,  7.3938e-01,\n",
       "          -4.8131e-03,  8.9747e-01],\n",
       "         [ 0.0000e+00,  2.2863e-02,  2.2337e-01,  ...,  7.8138e-03,\n",
       "           1.2037e-01,  3.1702e-03]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn(batch_x, batch_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dict['t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
